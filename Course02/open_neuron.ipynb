{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "# С чего все началось\n",
    "\n",
    "Для ознакомления с тем, что такое перцептрон, да и в целом как все начиналось, можно почитать статью на Википедии. Там представлена краткая история, довольно подробное объяснение, и в целом всё, что нам потребуется, и даже больше. В статье, помимо прочего, в разделе \"Историческая классификация\" говорится следующее:\n",
    "\n",
    "*\"Понятие перцептрона имеет интересную, но незавидную историю. В результате неразвитой терминологии нейронных сетей прошлых лет, резкой критики и непонимания задач исследования перцептронов, а иногда и ложного освещения прессой, изначальный смысл этого понятия исказился.\"*\n",
    "\n",
    "И далее:\n",
    "\n",
    "*\"Сравнивая разработки Розенблатта и современные обзоры и статьи, можно выделить 4 довольно обособленных класса перцептронов:\"*\n",
    "1. **Перцептрон с одним скрытым слоем**: Классический перцептрон, описанный в книгах Розенблатта. Содержит по одному слою S-, A- и R-элементов.\n",
    "2. **Однослойный перцептрон**: Простейшая сеть прямого распространения с входами, напрямую соединёнными с выходами. Это линейный классификатор, который не может решать задачи с нелинейными зависимостями, такие как XOR например.\n",
    "3. **Многослойный перцептрон (по Розенблатту)**: Перцептрон с дополнительными слоями A-элементов. Анализировался Розенблаттом в его книге.\n",
    "4. **Многослойный перцептрон (по Румельхарту)**: Включает дополнительные слои A-элементов и обучается методом обратного распространения ошибки. Является расширением перцептрона Розенблатта.\n",
    "\n",
    "Также полезно будет ознакомиться с разделами \"Алгоритмы обучения\" и \"Традиционные заблуждения\". Пересказывать всю статью не вижу смысла. Разбирать подробно различные реализации и писать для них код также не имеет смысла, так как с тех пор многое изменилось, хотя путаница в терминологии тех лет, на мой взгляд, всё ещё остаётся. Лично для себя я выделил несколько понятий, которые на мой взгляд являются ключевыми. Эти понятия я и собираюсь разобрать, и на их основе писать свою реализацию нейронной сети.\n",
    "\n",
    "Итак, по порядку:\n",
    "1. **Перцептрон/нейрон (однослойный перцептрон)**: Простейшая сеть прямого распространения с входами, напрямую соединёнными с выходами. Это линейный классификатор, который не может решать задачи с нелинейными зависимостями, такие как XOR например. Для простоты такой объект я буду называть перцептроном или нейроном.\n",
    "2. **Нейронная сеть (многослойный перцептрон)**: Включает дополнительные слои и обучается методом обратного распространения ошибки. Является расширением перцептрона Розенблатта. Для простоты это я буду называть нейронной сетью.\n",
    "3. **Общий алгоритм обучения**: обучение с учителем, метод обратного распространения ошибки.\n",
    "\n",
    "Эти три пункта я взял за основу, и вокруг них будет написан весь код. Как видите, по сравнению со статьей на Википедии, я значительно всё упростил, но, забегая вперед, скажу, что в финальной реализации нам даже такое, казалось бы, основное понятие как нейрон не особенно будет нужно, потому что все вычисления будут происходить на уровне слоев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "## 1. Еще не Перцептрон\n",
    "\n",
    "**Краткое вступление о том, что такое перцептрон.**\n",
    "\n",
    "Перцептрон был изобретён в 1957 году Фрэнком Розенблаттом, американским психологом и специалистом по нейронным сетям. Он разработал перцептрон как алгоритм машинного обучения, который может классифицировать входные данные на основе их линейных свойств. Перцептрон представлял собой одну из первых моделей искусственного нейрона, способную к обучению и распознаванию образов. Таким образом, понятие перцептрон можно кратко описать как алгоритм для классификации данных. Давайте попробуем создать такой алгоритм."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "### 1.1 Общий алгоритм (обучение с учителем)\n",
    "\n",
    "Начну не с самого перцептрона как объекта/нейрона, а с общего алгоритма задачи. Тут, на самом деле, можно придраться и сказать что перцептрон это и есть алгоритм. Повторюсь, что тут присутствует некоторая путанница. Переводится перцептрон с английского как восприятие. То есть это в принципе некое понятие которое моделирует процесс человеческого восприятия. В той же Википедии есть описание перцептрона так его описывал Розенблатт, а так же различные виды перцептрона и прочее. Я же выбрал однослойный перцептрон который фактически является формальным нейроном. \n",
    "\n",
    "Итак, предположим, что у нас есть какие-то данные, которые мы назовём входными данными (сигналами). Также мы знаем, каким должен быть результат — назовём его выходными данными. Наша задача — написать программу, которая будет получать на входе эти данные, затем производить над ними определённые вычисления (сложение/умножение входных данных на некоторые заданные значения) и выдавать ответ. Если этот ответ не соответствует ожидаемому, программа должна изменить некоторые из своих параметров, чтобы ответы совпадали.\n",
    "\n",
    "Кажется запутанным? На самом деле, всё гораздо проще, чем может показаться на первый взгляд. По сути, нам нужно найти решение уравнения путём \"подбора\"/изменения некоторых его переменных. Эти переменные можно назвать коэффициентами, или, как их общепринято называть, весами и смещением."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процесс обучения из 5 эпох\n",
      "Epoch 1/5, weights: -2.75, z: -2.75, prediction (output): 0\n",
      "Epoch 2/5, weights: -1.75, z: -1.75, prediction (output): 0\n",
      "Epoch 3/5, weights: -0.75, z: -0.75, prediction (output): 0\n",
      "Epoch 4/5, weights: 0.25, z: 0.25, prediction (output): 1\n",
      "Epoch 5/5, weights: 0.25, z: 0.25, prediction (output): 1\n"
     ]
    }
   ],
   "source": [
    "# Общий алгоритм обучения с учителем (упрощенный)\n",
    "\n",
    "# Входные данные (x) и целевая метка (y) (ожидаемый результат)\n",
    "x = 1\n",
    "y = 1\n",
    "\n",
    "# Гиперпараметры (этими параметрами мы можем влиять на процесс обучения)\n",
    "epochs = 5  # количество итераций для изменения веса и смещения в процессе обучения\n",
    "\n",
    "# Вес и смещение\n",
    "weights = -2.75  # начальные веса (этот параметр мы будем \"тренировать\"/изменять в процессе обучения)\n",
    "\n",
    "print(f'Процесс обучения из {epochs} эпох')\n",
    "# Обучение (процесс подбора/изменения весов для нахождения решения задачи)\n",
    "for epoch in range(epochs):\n",
    "    # Вычисление взвешенной (weight) суммы входного сигнала (x)\n",
    "    z = x * weights\n",
    "    \n",
    "    # Активация\n",
    "    prediction = 1 if z > 0 else 0\n",
    "    \n",
    "    # Отладочная информация\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, weights: {weights:.2f}, z: {z:.2f}, prediction (output): {prediction}')\n",
    "\n",
    "    # Обновление/изменение весов\n",
    "    if prediction != y:\n",
    "        if prediction == 0:\n",
    "            weights += x\n",
    "        if prediction == 1:\n",
    "            weights -= x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "Данный код демонстрирует общий алгоритм обучения. Конечно, на самом деле, алгоритм обучения нейронной сети несколько сложнее, но в целом похож. В коде пока нет никакой сети и даже нет никаких нейронов или перцептронов, а также отсутствует одна из важнейших концепций, такая как МОР (метод обратного распространения ошибки). Однако, в нем есть такие понятия как вычисление взвешенной суммы, активация и обучение весов. В целом, код демонстрирует общий алгоритм того, что происходит при обучении.\n",
    "\n",
    "Код написан специально максимально упрощенно, без использования массивов, матриц, сторонних библиотек, функций, ООП и других сложных концепций. Все это будет добавляться постепенно. В конце у нас будет полноценная реализация нейронной сети со слоями и нейронами на основе объектов и классов, с множеством различных функций и даже небольшим ~~костылем~~ классом для Keras, с помощью которого мы сможем сравнить результаты работы нашей простой нейронной сети с результатами, которые выдает аналогичная нейронная сеть, построенная на Keras.\n",
    "\n",
    "Общие понятия и терминология:\n",
    "- **Входные данные (`x`)**: Набор данных, подаваемый на вход модели (сети/слоя/нейрона) для обучения или предсказания. Обычно представляется в виде матрицы `X`, где строки соответствуют примерам, а столбцы — признакам. В начале мы будем пользоваться простыми списками в котороых каждый элемент это значение некоторго параметра объекта или фича от английского features. В примере у нас в качестве входных данных был просто объект с одним признаком `x = 1`. \n",
    "- **Целевая метка (`y`)**: Значения, которые модель должна предсказать. В задаче классификации это могут быть классы, а в задаче регрессии — числовые значения.\n",
    "- **Вес(а) (`weights`)**: Параметры модели, которые обучаются в процессе тренировки. Влияние каждого признака на итоговое предсказание регулируется весами. В примере был всего один вес так как у нас всего один входной сигнал `x = 1`.\n",
    "- **Смещение (`bias`)**: Дополнительный параметр модели, который помогает лучше подгонять модель под данные. Он позволяет модели предсказывать ненулевые значения, даже если все входные признаки равны нулю. В примере не использовался.\n",
    "- **Значение `z` (значение функции или вычисленное значение взвешенной суммы входных данных и смещения)**: Промежуточное значение, вычисляемое как линейная комбинация входных данных и весов, с добавлением смещения. Формула: `z = x * weights + bias`. В примере не было смещения.\n",
    "- **Функция активации (activation function или просто `activation`)**: Функция, применяемая к промежуточному значению `z`, чтобы ввести нелинейность в модель и помочь ей решать сложные задачи. Пример: `ReLU (Rectified Linear Unit)`, `sigmoid`, `tanh`. У перцептрона который мы создадим ступенчатая функция активации которая называется часто `heaviside`. В Википедии про функцию Хэвисайда сказано следующее: \"Функция Хевисайда (единичная ступенчатая функция, функция единичного скачка, включённая единица, «ступенька») — кусочно-постоянная функция, равная нулю для отрицательных значений аргумента и единице — для положительных. В нуле эта функция, вообще говоря, не определена, однако её обычно доопределяют в этой точке некоторым числом, чтобы область определения функции содержала все точки действительной оси. Чаще всего неважно, какое значение функция принимает в нуле, поэтому могут использоваться различные определения функции Хевисайда, удобные по тем или иным соображениям\"\n",
    "- **Предсказание (`prediction`)**: Значение, которое модель возвращает после обработки входных данных (вычисление взвешенной суммы и активация). В идеале оно должно совпадать с истинном значением (`y`). В задаче классификации, например, это может быть класс, к которому, по мнению модели, относится входной пример."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "### 1.2 Разбор результата алгоритма обучения\n",
    "\n",
    "Итак, давайте разберём и сразу же улучшим наш код. На самом деле, задача, которую мы решаем выше, довольно бесполезная и не имеет практического смысла. Повторюсь, она лишь демонстрирует алгоритм обучения нейрона/перцептрона. То есть она показывает, что алгоритм получает входные данные, производит с ними определённые операции (сложение/умножение), сравнивает результат с тем, который мы задали как правильный, и если ответ не совпадает, алгоритм корректирует вес в нужную сторону так, чтобы ответ совпадал с верным.\n",
    "\n",
    "Изначально мы задали вес как: `weight = -2.75`. Значения весов перед обучением выбираются случайным образом. И мы хотим чтобы наш перцептрон от этих случайных весов перешел к весам которые бы решали нашу задачу. Наши входные данные были просто одним числом: `x = 1`, и мы сказали, что правильный ответ должен быть равен `y = 1`. Наша функция вычисления `y` выглядит так: `z = x * weight`. Дальше мы применяем функцию активации к `z`, а именно, проверяем если `z > 0` то считаем что мы предсказали 1, а если `z <= 0`, то счиатем что мы предсказали 0. Получается: `z = 1 * (-2.75) = -2.75`. Предсказание `prediction = 0`, так как `-2,75 < 0`. Так как ответ не сошелся, то проверяем `prediction == 0`, если да, то увеличиваем веса, `weight += 1`, Вес станет -1.75.\n",
    "\n",
    "Первая эпоха завершена. Теперь у нас `weight = -1.75`. Какой же теперь `z`? `z = -1.75 * 1 = -1.75`. Напомню, что при начальных значениях веса `z` был `-2.75`. Мы видим, что результат стал ближе к правильному, но пока `z <= 0` наша активация все равно возвращает 0, что не соответствует правильному ответу. Но мы указали 5 эпох для обучения, поэтому начинаем вторую. Можете сами подставить вес в формулу `z = x * weight`, посчитать результат, и убедиться в том, что наш вес станет: `weight = -0.75`. Теперь `z = 1 * (-0.75) = -0.75`, то есть ещё ближе к нашему правильному ответу. Проделав все 5 эпох обучения мы еще приблизимся к нашему правильному ответу. На самом деле уже на 4 эпохе мы получим правильный ответ. И далее можно было бы остановить обучение проверив что ответ соответствует, но мы проделаем еще одну эпоху и убедимся, что если ответ правильный, то у нас веса перестают обучаться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "### 1.3 Выводы\n",
    "\n",
    "Как было сказано, наш код демонстрирует общий алгоритм обучения и объясняет некоторые базовые понятия вроде входные данные, целевая метка, вес, активация и прочее. Так как стояла задача продемонстировать общий процесс обучения, то многие деталти были упущены для упрощения и пример, в целом, не имеет никакго практического смысла. Подобные примеры наглядно демонстрируют основные понятия и общие принцыпы. Перед тем как перейти к более осмысленным примерам посмотрим как бы повел себя алгоритм если бы целевая метка была 0, а не 1 (`y = 0`), но с добавлением смещения и некоторыми изменениями в формуле изменения весов и смещения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процесс обучения из 5 эпох\n",
      "Эпоха обучения 1/5, weight: -2.75, bias: 5.25, z: 2.50, prediction: 1, error: -1\n",
      "Эпоха обучения 2/5, weight: -3.75, bias: 4.25, z: 0.50, prediction: 1, error: -1\n",
      "Эпоха обучения 3/5, weight: -4.75, bias: 3.25, z: -1.50, prediction: 0, error: 0\n",
      "Эпоха обучения 4/5, weight: -4.75, bias: 3.25, z: -1.50, prediction: 0, error: 0\n",
      "Эпоха обучения 5/5, weight: -4.75, bias: 3.25, z: -1.50, prediction: 0, error: 0\n"
     ]
    }
   ],
   "source": [
    "# Общий алгоритм (обучение с учителем)\n",
    "\n",
    "# Входные данные (x) и целевая метка (y) (ожидаемый результат)\n",
    "x = 1\n",
    "y = 0\n",
    "\n",
    "# Гиперпараметры (этими параметрами мы можем влиять на процесс обучения)\n",
    "epochs = 5  # количество итераций для изменения веса и смещения в процессе обучения\n",
    "\n",
    "# Вес и смещение\n",
    "weights = -2.75  # начальный вес (этот параметр мы будем \"тренировать\"/изменять в процессе обучения)\n",
    "bias = 5.25  # начальное смещение (этот параметр мы будем \"тренировать\"/изменять в процессе обучения)\n",
    "\n",
    "print(f'Процесс обучения из {epochs} эпох')\n",
    "# Обучение (процесс подбора/изменения весов и смещения для нахождения решения задачи)\n",
    "for epoch in range(epochs):\n",
    "    # Вычисление взвешенной (weight) суммы входного сигнала (x) и смещения (bias)\n",
    "    z = x * weights + bias  # это то, что выдает/предсказывает наш алгоритм\n",
    "    \n",
    "    # Активация\n",
    "    prediction = 1 if z > 0 else 0\n",
    "    \n",
    "    # Вычисление ошибки\n",
    "    error = y - prediction\n",
    "\n",
    "    # Отладочная информация\n",
    "    print(f'Эпоха обучения {epoch + 1}/{epochs}, weight: {weights:.2f}, bias: {bias:.2f}, z: {z:.2f}, prediction: {prediction}, error: {error}')\n",
    "\n",
    "    # Обновление/изменение веса и смещения на основе ошибки error\n",
    "    weights += error * x\n",
    "    bias += error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "Теперь мы видим, что изначально у нас было предсказание 1 а мы ожидали 0. Используя ошибку предсказания мы немного подкоррестировали вес и смещение и получили уже на третьей эпохе нужный результат. В примере так же видно как обучается наше смещение.\n",
    "\n",
    "Общие понятия и терминология:\n",
    "- **Ошибка (`error`)**: Разница между предсказанным значением и реальной целевой меткой. Это еще не та ошибка, которая используется для оценки качества модели. Пока это просто для того, чтобы понять, нужно уменьшать или увеличивать веса и смещение. Ошибка которая может нам помочь оценить качество предсказаний это, например, MSE (Mean Squared Error) и пока мы ее не используем. Так же можно заметить, что мы вычисляем ошибку как `y - prediction`, а в первом предложении говорится, что это разница `prediction - y`. На самом деле это не принципиально. Просто мы пользуемся `y - prediction` так как это интуитивно более понятно. Но мы можем так же пользоватьмся и `prediction - y` просто тогда мы должны менять веса не `weights +=` а `weights -=` и далее мы именно так и будем делать. Пока мы будем пользоваться только понятием `error` и для упрощения считать ошибку как `y - prediction`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "### 1.4 Описание процесса подготовки и обучения нейронной сети\n",
    "\n",
    "1. **Подготовка данных**: Определяем входные данные `X` или просто один пример `x` и целевые метки `y`.\n",
    "2. **Инициализация модели**: Устанавливаем начальные значения весов и смещений.\n",
    "3. **Метод/процесс прямого распространения (Forward Pass)**:\n",
    "   - \"Подаем\" наши данные в сеть/нейрон. \n",
    "   - Вычисляем промежуточное значение `z` для всех нейронов/слов сети или просто для одного нейрона.\n",
    "   - Применяем функцию активации к `z`, получая `a` (`output`).\n",
    "4. **Вычисление ошибки**:\n",
    "   - Сравниваем значение активированного выхода `a` (`output`) с истинным значением `y`.\n",
    "   - Используем функцию потерь для расчета ошибки. Пока просто будем использовать значение `error`.\n",
    "5. **Метод/процесс обратного распространения (Backward Pass)**:\n",
    "   - Вычисляем градиенты функции потерь по отношению к весам и смещениям на выходном слое/нейроне. Вот тут мы пока не будем пользоваться понятием градиент и производная. Да и в целом пока мы не перейдем непосредственно к сети из слоев с нейронами мы не будем называть это методом обратного распространения ошибки (МОР), так как она (ошибка) пока еще не распространияется у нас, то есть не передается в предыдущие слои сети.\n",
    "   - Обновляем веса и смещения с использованием алгоритма оптимизации, например, градиентного спуска. Тут туже пока несколько упростим процесс и не будем применять понятие \"алгоритм оптимизации\" опять же для упрощения на начальных этапах.\n",
    "6. **Повторение**:\n",
    "   - Повторяем шаги 3-5 на протяжении заданного количества эпох или до достижения приемлемого уровня ошибки.\n",
    "7. **Предсказание**:\n",
    "   - После обучения модели, подаем новые данные на вход и получаем предсказание. Так как для начала мы не будем использовать большие выборки которые должны быть разделены на обучающую и тестовую, то проедсказывать мы будем то на чем обучались. Это не совсем правильно, но, опять же, зависит от задачи.\n",
    "\n",
    "В итоге хочется сказать, что некоторые неточности в терминологии допущены вынужденно/намерено для общего упрощения понимания задачи. В дальнейшем все эти неточности будут естесственным образом исправлены.\n",
    "\n",
    "Итак давайте перейдем от задачи которая в принципе имела мало смысла к чему-то более осмысленному. А именно давайте теперь рассмотрим некий один объект `x` нашей некой выборки `X`, у которого есть два признака. Те есть `x = [1, 0]`. Перепишем наш код с учетом той терминологии что мы описали выше, также обобщим формулу вычисления `z`, и добавим еще функций. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процесс обучения из 5 эпох\n",
      "Эпоха обучения 1/5, weights: [-0.5, -1.25], bias: 5.25, prediction: 1, error: -1\n",
      "Эпоха обучения 2/5, weights: [-1.5, -1.25], bias: 4.25, prediction: 1, error: -1\n",
      "Эпоха обучения 3/5, weights: [-2.5, -1.25], bias: 3.25, prediction: 1, error: -1\n",
      "Эпоха обучения 4/5, weights: [-3.5, -1.25], bias: 2.25, prediction: 0, error: 0\n",
      "Эпоха обучения 5/5, weights: [-3.5, -1.25], bias: 2.25, prediction: 0, error: 0\n"
     ]
    }
   ],
   "source": [
    "# Общий алгоритм\n",
    "\n",
    "# Входные данные и целевая метка (ожидаемый результат)\n",
    "x = [1, 0]  # объект с двумя признаками\n",
    "y = 0\n",
    "\n",
    "# Гиперпараметры (этими параметрами мы можем влиять на процесс обучения)\n",
    "epochs = 5  # количество итераций для изменения весов и смещения в процессе обучения\n",
    "\n",
    "# Веса и смещение\n",
    "weights = [-0.5, -1.25]  # начальные веса (эти параметры мы будем \"тренировать\"/изменять в процессе обучения)\n",
    "bias = 5.25  # начальное смещение (этот параметр мы будем \"тренировать\"/изменять в процессе обучения)\n",
    "\n",
    "# Функция активации: ступенчатая/пороговая функция\n",
    "def activation(z):\n",
    "    return 0 if z < 0.5 else 1\n",
    "\n",
    "# Функция предсказания\n",
    "def predict(x):\n",
    "    # z = x1*w1 + x2*w2 + ... + xn*wn + bias\n",
    "    z = sum(xi * wi for xi, wi in zip(x, weights)) + bias  # взвешенная сумма\n",
    "    a = activation(z)  # активация\n",
    "    return a  # возвращаем значение активации (prediction)\n",
    "\n",
    "# Функция обновления/изменения весов и смещения на основе ошибки\n",
    "def update(weights, bias, error, x):\n",
    "    for i in range(len(weights)):\n",
    "        weights[i] += error * x[i]\n",
    "    bias += error\n",
    "    return weights, bias\n",
    "\n",
    "print(f'Процесс обучения из {epochs} эпох')\n",
    "# Обучение (процесс подбора/изменения весов и смещения для нахождения решения задачи)\n",
    "for epoch in range(epochs):\n",
    "    # Получение предсказания\n",
    "    prediction = predict(x)\n",
    "    \n",
    "    # Вычисление ошибки\n",
    "    error = y - prediction\n",
    "    \n",
    "    # Отладочная информация\n",
    "    rounded_weights = [round(weight, 2) for weight in weights]  # округляем веса до двух знаков после запятой для удобочитаемости\n",
    "    rounded_bias = round(bias, 2)  # округляем смещение до двух знаков после запятой для удобочитаемости\n",
    "    print(f'Эпоха обучения {epoch + 1}/{epochs}, weights: {rounded_weights}, bias: {rounded_bias}, prediction: {prediction}, error: {error}')\n",
    "\n",
    "    # Обновление/изменение весов и смещения на основе ошибки\n",
    "    weights, bias = update(weights, bias, error, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "В целом нет смысла разбирать всё повторно, так как разбор аналогичен предыдущему. Главное - понять, что объекты `x`, подаваемые в сеть, будут иметь свои признаки, и сеть должна обучить веса таким образом, чтобы правильно классифицировать эти объекты (в случае задачи классификации). На что можно обратить внимание, так это на то, что, как видно из результатов, наш второй вес не обучается. Это происходит потому, что наш единственный объект `x` имеет два признака, и один из них равен 0. Поэтому при расчёте изменения второго веса происходит умножение на 0, и, следовательно, второй вес остаётся неизменным. Так же можно заметить что в функции активации я использую значение 0.5 вместо 0. В целом это ничего не меняет, просто раз уж мы говорим пока о бинарной классификации, то в такой классификации общепринято обозначать объекты одного класса 0, а объекты другого класса 1. Логично, что некоторое среднее значение которое как бы разделяет эти два класса это 0.5. Все что меньше 0.5 это считать 0, а все что выше и равно 0.5 это 1. Повторюсь, что в целом это ничего не меняет, просто, выглядит более логично. В дальнейшем буду называть такую функцию функцией Хэвисайда.  \n",
    "\n",
    "В следующем шаге хотелось бы перейти к ООП и представить всю модель сети как совокупности взаимодействующих между собой объектов (нейронов, слоёв, оптимизаторов и других). Но перед тем как это сделать, сделаем ещё один небольшой шажок: добавим в наш набор ещё один признак и посмотрим на процесс обучения, чтобы окончательно закрепить понимание того, что происходит при обучении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "### 1.5 Почти Логическое И (AND)\n",
    "\n",
    "Что такое \"Логическое И\" (AND) и как наш Перцептрон (нейрон с пороговой функцией активации) решает эту задачу, мы подробно рассмотрим далее. Перед окончательным переходом к ООП давайте кратко рассмотрим ещё один пример, о котором было сказано ранее. Прежде чем писать класс для Перцептрона, проанализируем выборку из двух объектов и посмотрим на процесс обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Тест до обучения\n",
      "Для входных данных [1, 0] предсказанное значение: 1, ожидаемое/истинное значение: 0\n",
      "Для входных данных [1, 1] предсказанное значение: 0, ожидаемое/истинное значение: 1\n",
      "\n",
      "Процесс обучения из 10 эпох\n",
      "Эпоха обучения 1/10, weights: [-0.5, -2.25], bias: 3.25\n",
      "Эпоха обучения 2/10, weights: [-0.5, -1.25], bias: 3.25\n",
      "Эпоха обучения 3/10, weights: [-0.5, -0.25], bias: 3.25\n",
      "Эпоха обучения 4/10, weights: [-1.5, -0.25], bias: 2.25\n",
      "Эпоха обучения 5/10, weights: [-1.5, 0.75], bias: 2.25\n",
      "Эпоха обучения 6/10, weights: [-1.5, 1.75], bias: 2.25\n",
      "Эпоха обучения 7/10, weights: [-2.5, 1.75], bias: 1.25\n",
      "Эпоха обучения 8/10, weights: [-2.5, 1.75], bias: 1.25\n",
      "Эпоха обучения 9/10, weights: [-2.5, 1.75], bias: 1.25\n",
      "Эпоха обучения 10/10, weights: [-2.5, 1.75], bias: 1.25\n",
      "\n",
      "Тест после обучения\n",
      "Для входных данных [1, 0] предсказанное значение: 0, ожидаемое/истинное значение: 0\n",
      "Для входных данных [1, 1] предсказанное значение: 1, ожидаемое/истинное значение: 1\n"
     ]
    }
   ],
   "source": [
    "# Общий алгоритм\n",
    "\n",
    "# Входные данные и целевая метка (ожидаемый результат)\n",
    "X = [[1, 0], [1, 1]]  # выборка объектов (два объекта в выборке каждый с двумя признаками)\n",
    "y = [0, 1]  # объект x = [1, 0] класса 0, объект x = [1, 1] класса 1\n",
    "\n",
    "# Гиперпараметры (этими параметрами мы можем влиять на процесс обучения)\n",
    "epochs = 10  # количество итераций для изменения весов и смещения в процессе обучения\n",
    "\n",
    "# Веса и смещение\n",
    "weights = [-0.5, -3.25]  # начальные веса (эти параметры мы будем \"тренировать\"/изменять в процессе обучения)\n",
    "bias = 3.25  # начальное смещение (этот параметр мы будем \"тренировать\"/изменять в процессе обучения)\n",
    "\n",
    "# Функция активации: ступенчатая/пороговая функция (порог 0.5)\n",
    "def activation(z):\n",
    "    return 0 if z < 0.5 else 1\n",
    "\n",
    "# Функция предсказания\n",
    "def predict(x):\n",
    "    # z = x1*w1 + x2*w2 + ... + xn*wn + bias\n",
    "    z = sum(xi * wi for xi, wi in zip(x, weights)) + bias  # взвешенная сумма\n",
    "    a = activation(z)  # активация\n",
    "    return a  # возвращаем значение активации (prediction)\n",
    "\n",
    "# Функция обновления/изменения весов и смещения на основе ошибки\n",
    "def update(weights, bias, error, x):\n",
    "    for i in range(len(weights)):\n",
    "        weights[i] += error * x[i]\n",
    "    bias += error\n",
    "    return weights, bias\n",
    "\n",
    "# Предсказание на обучающем примере\n",
    "print('\\nТест до обучения')\n",
    "for x, y_true in zip(X, y):\n",
    "    prediction = predict(x)\n",
    "    print(f'Для входных данных {x} предсказанное значение: {prediction}, ожидаемое/истинное значение: {y_true}')\n",
    "\n",
    "print(f'\\nПроцесс обучения из {epochs} эпох')\n",
    "# Обучение (процесс подбора/изменения весов и смещения для нахождения решения задачи)\n",
    "for epoch in range(epochs):\n",
    "    for x, y_true in zip(X, y):    \n",
    "        # Получение предсказания\n",
    "        prediction = predict(x)\n",
    "        \n",
    "        # Вычисление ошибки\n",
    "        error = y_true - prediction\n",
    "\n",
    "        # Обновление/изменение веса и смещения на основе ошибки\n",
    "        weights, bias = update(weights, bias, error, x)\n",
    "\n",
    "    # Отладочная информация\n",
    "    rounded_weights = [round(weight, 2) for weight in weights]  # округляем веса до двух знаков после запятой для удобочитаемости\n",
    "    rounded_bias = round(bias, 2)  # округляем смещение до двух знаков после запятой для удобочитаемости\n",
    "    print(f'Эпоха обучения {epoch + 1}/{epochs}, weights: {rounded_weights}, bias: {rounded_bias}')\n",
    "\n",
    "# Предсказание на обучающем примере\n",
    "print('\\nТест после обучения')\n",
    "for x, y_true in zip(X, y):\n",
    "    prediction = predict(x)\n",
    "    print(f'Для входных данных {x} предсказанное значение: {prediction}, ожидаемое/истинное значение: {y_true}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "В отличии от предыдущего примера, можно заметить, что в процессе обучения обучаются уже оба веса и смещение. Таким образом наша программа с изначальными весами неправильно классифицировала оба объекта, но после 7 эпох обучения веса и смещение были подстроены так, что оба объекта стали классифицироваться правильно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "## 2. Почти Перцептрон"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "Почему почти станет понятно чуть дальше. Пока давайте разберем код для класса Perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс для Перцептрона\n",
    "class Perceptron:\n",
    "    # Встроенный метод для инициализации объекта\n",
    "    def __init__(self, weights, bias=None):\n",
    "        \"\"\"\n",
    "        Инициализирует перцептрон с заданными весами и смещением.\n",
    "        \n",
    "        :param weights: Список начальных весов.\n",
    "        :param bias: Начальное значение смещения. По умолчанию None.\n",
    "        \"\"\"\n",
    "        self.inputs = None                  # входные значения (набор признкаков одного объекта x из выборки X)\n",
    "        self.weights = weights              # веса\n",
    "        self.bias = bias                    # смещение\n",
    "        self.z = None                       # взвешенная сумма входов + смещение (вычисляется позже в методе forward)\n",
    "        self.activation = self.heaviside    # функция активации\n",
    "        self.a = None                       # результат применения активационной функции (вычисляется позже в методе forward)\n",
    "    \n",
    "    # Метод для активации (ступенчатая/пороговая функция активации)\n",
    "    def heaviside(self, z):\n",
    "        \"\"\"\n",
    "        Пороговая функция активации (функция Хевисайда).\n",
    "        \n",
    "        :param z: Взвешенная сумма входов и смещения.\n",
    "        :return: 0, если z < 0.5, иначе 1.\n",
    "        \"\"\"\n",
    "        return 0 if z < 0.5 else 1\n",
    "\n",
    "    # Метод для подачи/\"прогона\" данных в/через перцептрон (Forward propagation)\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Подает/\"прогоняет\" данные в/через перцептрон, вычисляет взвешенную сумму и применяет функцию активации.\n",
    "        \n",
    "        :param inputs: Список входных значений (набор признаков объекта).\n",
    "        :return: Результат применения функции активации.\n",
    "        \"\"\"\n",
    "        # Сохраняем поданные в перцептрон входные данные в переменной-атрибуте объекта\n",
    "        self.inputs = inputs\n",
    "        # Рассчитываем взвешенную сумму (z)\n",
    "        self.z = sum(xi * wi for xi, wi in zip(self.inputs, self.weights)) + (self.bias if self.bias is not None else 0)\n",
    "        # Применяем функцию активации к z\n",
    "        self.a = self.activation(self.z)\n",
    "        return self.a  # возвращаем результат активации (выход/ответ перцептрона output)\n",
    "    \n",
    "    # Метод для получения предсказаний по всей выборке\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Подает/\"прогоняет\" весь набор данных в/через перцептрон.\n",
    "        \n",
    "        :param X: Список списков или массив входных значений (набор признаков объекта).\n",
    "        :return: Список результатов активации для каждого набора входных значений (для каждого объекта из выборки).\n",
    "        \"\"\"\n",
    "        return [self.forward(x) for x in X]\n",
    "    \n",
    "    # Встроенный метод для строкового представления объекта\n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Возвращает строковое представление объекта перцептрон.\n",
    "        \n",
    "        :return: Строка с текущими значениями атрибутов перцептрона (значениями атрибутов рассчитанные при последнем \"прогоне\").\n",
    "        \"\"\"\n",
    "        # self.forward(self.inputs) if self.inputs is not None else ...  # рассчитываем актуальные значения z и a\n",
    "        return f'Perceptron, inputs: {self.inputs}, weights: {self.weights}, bias: {self.bias}, z: {self.z}, ' \\\n",
    "               f'activation: {self.activation.__name__}, a (output): {self.a}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "Перед нами класс с названием `Perceptron`. Для чего он нужен? Он нужен для создания разных объектов этого класса. Что такое объект? Тут приходит на ум только бессмысленное объяснение, вроде того, что объект это объект. Так как это не курс по ООП, я попытаюсь объяснить только общие моменты или только то, что мы непосредственно используем.\n",
    "\n",
    "Итак, объект — это некая сущность ~~в виде гномика~~, которая обладает какими-то свойствами/атрибутами, если мы говорим о классе объекта и какими-то методами (для понимания это некие функции). Этот самый объект может принимать какие-то данные, как та же функция, например, и производить с этими данными какие-то вычисления, менять как-то свое состояние (значение своих параметров), взаимодействовать с другими объектами или функциями при этом в одной программе может быть много объектов разных классов и они могут каким-то образом друг с другом взаимодействовать описывая какие-то сложные процессы и понятия. Например дальше мы будем объеденять несколько объектов класса нейрон в объекте класса слой, а объекты класса слой будут определенным образом взаимодействовать между собой, а все это вместе будет объектом класса нейронная сеть со своими методами и свойствами. В Python, кстати, все является объектами.\n",
    "\n",
    "Наверное, звучит довольно запутанно, но на самом деле, когда разобрался в концепции ООП, то потом все подряд начинаешь писать в этом стиле. Зачем это нужно? Дело в том, что при написании достаточно сложных программ и при решении сложных задач довольно быстро сталкиваешься с тем, что код разрастается, и поддерживать и прослеживать логику становится все сложнее. В коде могут быть сотни и тысячи разных функций и еще больше переменных и параметров. Это все бесконечно усложняет.\n",
    "\n",
    "Поэтому переход к объектно-ориентированной концепции программирования в значительной мере упрощает понимание кода и позволяет описывать более сложные сущности и оперировать более сложными абстракциями, что в свою очередь помогает создавать более сложные в плане продвинутости программы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "В нашей первоначальной программе были некоторые переменные, которые по смыслу можно отнести к некоторой общей группе или классу. Не путать с понятием класса, которым мы оперируем при классификации наших данных. Имеется в виду, что, например, переменные `weights`, `bias`, `z`, `a` (output) между собой связаны, и их можно представить как некие свойства некоторого объекта. То есть наш объект `perceptron` будет сам в себе хранить веса и смещение, например.\n",
    "\n",
    "Так же и с функциями. Например, функция `forward`, которая принимает некоторые данные и вычисляет `z` и `a`, или функция `predict`, которая принимает нашу выборку и передает по отдельности каждый элемент выборки в `forward`, или функцию активации тоже можно отнести к нашему объекту `perceptron`. То есть эти переменные и эти функции как бы связаны между собой и объединены по смыслу с нашим объектом `perceptron`.\n",
    "\n",
    "Поэтому мы создаем общий класс с названием `Perceptron` и \"помещаем\" в него наши переменные, которые мы называем атрибутами, и функции, которые мы называем методами. Когда мы создаем сам объект `perceptron` на основе этого класса, этот объект хранит в себе свои значения переменных и может быть в разные моменты вызван для произведения нужных нам вычислений. При этом этих объектов может быть и несколько, что нам обязательно нужно будет, когда мы столкнемся с тем, что наш один объект класса перцептрон не способен решить некоторые задачи, а вот уже три этих объекта объединенные в сеть, эти задачи решают."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "### 2.1 Описание атрибутов и методов класса Perceptron\n",
    "\n",
    "**Метод `__init__`**:\n",
    "- Инициализирует перцептрон с заданными весами и смещением.\n",
    "- weights - начальные веса.\n",
    "- bias - начальное значение смещения (по умолчанию None).\n",
    "\n",
    "**Метод `heaviside`**:\n",
    "- Возвращает 1, если z >= 0.5, иначе 0.\n",
    "\n",
    "**Метод `forward`**:\n",
    "- Функция подает/\"прогоняет\" данные в/через перцептрон, вычисляет взвешенную сумму и применяет функцию активации.\n",
    "- Возвращает результат применения функции активации.\n",
    "\n",
    "**Метод `predict`**:\n",
    "- Функция предсказывает выходные значения всего набора данных.\n",
    "- Возвращает список результатов активации для каждого набора входных значений.\n",
    "\n",
    "**Метод `__str__`**:\n",
    "- Возвращает строковое представление объекта перцептрона с текущими значениями атрибутов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "### 2.2 Магические методы (дополнитеьное пояснение) \n",
    "\n",
    "У объекта могут быть втроенные или как их еще называют магические методы. В Python они выделяются двумя подчеркиваниями в начале и в конце имени. Например `__new__`, `__init__`, `__call__`, `__srt__` и другие. Эти методы позволяют получать разное поведение объекта в разных условиях/ситуациях. Что это значит? Когда мы создаем объект и пишем строку `perceptron = Perceptron(weights=[-0.5, -1.25], bias=1.75)` то вызывается метод `__init__` нашего класса Perceptron и ему могут быть переданы два параметра: `weights` и `bias`. Причем `weights` обязательно должен быть указан, а `bias` если не укажем то примет значение по-умолчанию `None` (на самом деле перед `__init__` будет вызван магический метод `__new__` но мы его пока не используем). То есть это поведение объекта при создании. Если мы например определили метод `__str__`, то при попытке напечатать наш объект: `print(perceptron)` - вызовется метод `__str__` и мы получим строку которую этот метод возвращает. Методы написанные нами вызываются у объекта путем указания их имени через точку. Например в результате выполнения строки `predictions = perceptron.predict(X)` в переменную `prediction` будет записан результат который вернет метод `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron, inputs: None, weights: [-0.5, -1.25], bias: 1.75, z: None, activation: heaviside, a (output): None\n"
     ]
    }
   ],
   "source": [
    "# Создаем объект класса Perceptron\n",
    "perceptron = Perceptron(weights=[-0.5, -1.25], bias=1.75)\n",
    "# Выводм текстовое представление объекта\n",
    "print(perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron, inputs: None, weights: [-0.5, -1.25], bias: 1.75, z: None, activation: heaviside, a (output): None\n",
      "\n",
      "Тест до обучения\n",
      "Для входных данных [[1, 0], [1, 1]] предсказанные значения: [1, 0], ожидаемые/истинные значения: [0, 1]\n",
      "\n",
      "Данные \"прогона\" последнего объекта\n",
      "Perceptron, inputs: [1, 1], weights: [-0.5, -1.25], bias: 1.75, z: 0.0, activation: heaviside, a (output): 0\n"
     ]
    }
   ],
   "source": [
    "# Входные данные и целевая метка (ожидаемый результат)\n",
    "X = [[1, 0], [1, 1]]  # выборка объектов (два объекта в выборке каждый с двумя признаками)\n",
    "y = [0, 1]  # объект x = [1, 0] класса 0, объект x = [1, 1] класса 1\n",
    "\n",
    "# Объявляем и инициализируем объект класса Perceptron\n",
    "perceptron = Perceptron(weights=[-0.5, -1.25], bias=1.75)\n",
    "print(perceptron)\n",
    "\n",
    "# Предсказания до обучения\n",
    "print('\\nТест до обучения')\n",
    "predictions = perceptron.predict(X)\n",
    "print(f'Для входных данных {X} предсказанные значения: {predictions}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "print('\\nДанные \"прогона\" последнего объекта')\n",
    "print(perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "Давайте сделаем еще одну мелочь, а именно добавим в наш класс магический метод `__call__`. Особой необходимости в этом нет, но как говорят: для закрепления пройденого материала. После добавления этого магического метода мы сможем подвать данные в наш объект и получать предсказание просто написав такой код: `predictions = perceprton(X)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс для Перцептрона\n",
    "class Perceptron:\n",
    "    # Встроенный метод для инициализации объекта\n",
    "    def __init__(self, weights, bias=None):\n",
    "        self.inputs = None                  # входные значения (набор признкаков одного объекта x из выборки X)\n",
    "        self.weights = weights              # веса\n",
    "        self.bias = bias                    # смещение\n",
    "        self.z = None                       # взвешенная сумма входов + смещение (вычисляется позже в методе forward)\n",
    "        self.activation = self.heaviside    # функция активации\n",
    "        self.a = None                       # результат применения активационной функции (вычисляется позже в методе forward)\n",
    "    \n",
    "    # Метод для активации (пороговая функция активации)\n",
    "    def heaviside(self, z):\n",
    "        return 0 if z < 0.5 else 1\n",
    "\n",
    "    # Метод для подачи/\"прогона\" данных в/через перцептрон, вычисления z и активации (выхода/ответа)\n",
    "    def forward(self, inputs):\n",
    "        # Сохраняем поданные в перцептрон входные данные в переменной-атрибуте объекта\n",
    "        self.inputs = inputs\n",
    "        # Рассчитываем взвешенную сумму (z)\n",
    "        self.z = sum(xi * wi for xi, wi in zip(self.inputs, self.weights)) + (self.bias if self.bias is not None else 0)\n",
    "        # Применяем функцию активации к z\n",
    "        self.a = self.activation(self.z)\n",
    "        return self.a  # возвращаем результат активации (выход/ответ перцептрона output)\n",
    "    \n",
    "    # Встроенный метод для вызова объекта как функции\n",
    "    def __call__(self, X):\n",
    "        return [self.forward(x) for x in X]\n",
    "\n",
    "    # Метод для получения предсказаний по всей выборке\n",
    "    def predict(self, X):\n",
    "        return self.__call__(X)\n",
    "    \n",
    "    # Встроенный метод для строкового представления объекта\n",
    "    def __str__(self):\n",
    "        # self.forward(self.inputs) if self.inputs is not None else ...  # рассчитываем актуальные значения z и a\n",
    "        return f'Perceptron, inputs: {self.inputs}, weights: {self.weights}, bias: {self.bias}, z: {self.z}, ' \\\n",
    "               f'activation: {self.activation.__name__}, a (output): {self.a}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron, inputs: None, weights: [-0.5, -1.25], bias: 1.75, z: None, activation: heaviside, a (output): None\n",
      "\n",
      "Тест до обучения\n",
      "Для входных данных [[1, 0], [1, 1]] предсказанные значения: [1, 0], ожидаемые/истинные значения: [0, 1]\n",
      "\n",
      "Данные \"прогона\" последнего объекта\n",
      "Perceptron, inputs: [1, 1], weights: [-0.5, -1.25], bias: 1.75, z: 0.0, activation: heaviside, a (output): 0\n"
     ]
    }
   ],
   "source": [
    "# Входные данные и целевая метка (ожидаемый результат)\n",
    "X = [[1, 0], [1, 1]]  # выборка объектов (два объекта в выборке каждый с двумя признаками)\n",
    "y = [0, 1]  # объект x = [1, 0] класса 0, объект x = [1, 1] класса 1\n",
    "\n",
    "# Объявляем и инициализируем объект класса Perceptron\n",
    "perceptron = Perceptron(weights=[-0.5, -1.25], bias=1.75)\n",
    "print(perceptron)\n",
    "\n",
    "# Предсказания до обучения\n",
    "print('\\nТест до обучения')\n",
    "predictions = perceptron(X)\n",
    "print(f'Для входных данных {X} предсказанные значения: {predictions}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "print('\\nДанные \"прогона\" последнего объекта')\n",
    "print(perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "Теперь мы оперируем таким понятием как перцептрон и можем также оперировать таким понятием как обучение перцептрона. То есть мы будем в цикле из первоначального кода вызывать наш перцептрон подавая в него данные и получая его предсказания. На основе этих предсказаний мы будем обучать его. Но перед этим добавим еще один метод в наш класс. А именно метод который будет обучать/изменять веса и смещение нашего объекта. Ведь логично что функция которая изменяет параметры самого объекта должна принадлежать этому же объекту. Это конечно не обязательно но вполне логично зачем нам оставлять ее как некую отдельную функцию если эта функция все-равно всегда работает только с этим объектом. Итак перенесем функцию `update` в наш класс и станет методом для обновления весов и смещения.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс для Перцептрона\n",
    "class Perceptron:\n",
    "    # Встроенный метод для инициализации объекта\n",
    "    def __init__(self, weights, bias=None):\n",
    "        self.inputs = None                  # входные значения (устанавливаются позже в методе forward)\n",
    "        self.weights = weights              # веса\n",
    "        self.bias = bias                    # смещение\n",
    "        self.z = None                       # взвешенная сумма входов + смещение (вычисляется позже в методе forward)\n",
    "        self.activation = self.heaviside    # функция активации\n",
    "        self.a = None                       # результат применения активационной функции (вычисляется позже в методе forward)\n",
    "    \n",
    "    # Метод для активации (пороговая функция активации)\n",
    "    def heaviside(self, z):\n",
    "        return 0 if z < 0.5 else 1\n",
    "\n",
    "    # Метод для подачи/\"прогона\" данных в/через перцептрон, вычисления z и активации (выхода/ответа)\n",
    "    def forward(self, x):\n",
    "        # Сохраняем поданные в перцептрон входные данные в переменной-атрибуте объекта\n",
    "        self.inputs = x\n",
    "        # Рассчитываем взвешенную сумму (z)\n",
    "        self.z = sum(xi * wi for xi, wi in zip(self.inputs, self.weights)) + (self.bias if self.bias is not None else 0)\n",
    "        # Применяем функцию активации к z\n",
    "        self.a = self.activation(self.z)\n",
    "        return self.a  # возвращаем результат активации (выход/ответ перцептрона output)\n",
    "    \n",
    "    # Метод для обновления/изменения весов и смещения на основе ошибки\n",
    "    def update(self, error, x):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] += error * x[i]\n",
    "        self.bias += error\n",
    "    \n",
    "    # Встроенный метод для вызова объекта как функции\n",
    "    def __call__(self, X):\n",
    "        return [self.forward(x) for x in X]\n",
    "\n",
    "    # Метод для получения предсказаний по всей выборке\n",
    "    def predict(self, X):\n",
    "        return self.__call__(X)\n",
    "    \n",
    "    # Встроенный метод для строкового представления объекта\n",
    "    def __str__(self):\n",
    "        # self.forward(self.inputs) if self.inputs is not None else ...  # рассчитываем актуальные значения z и a\n",
    "        return f'Perceptron, inputs: {self.inputs}, weights: {self.weights}, bias: {self.bias}, z: {self.z}, ' \\\n",
    "               f'activation: {self.activation.__name__}, a (output): {self.a}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron, inputs: None, weights: [-0.5, -1.25], bias: 1.75, z: None, activation: heaviside, a (output): None\n",
      "\n",
      "Тест до обучения\n",
      "Для входных данных [[1, 0], [1, 1]] предсказанные значения: [1, 0], ожидаемые/истинные значения: [0, 1]\n",
      "\n",
      "Процесс обучения из 10 эпох\n",
      "Эпоха обучения 1/10, weights: [-0.5, -0.25], bias: 1.75\n",
      "Эпоха обучения 2/10, weights: [-0.5, 0.75], bias: 1.75\n",
      "Эпоха обучения 3/10, weights: [-0.5, 1.75], bias: 1.75\n",
      "Эпоха обучения 4/10, weights: [-1.5, 1.75], bias: 0.75\n",
      "Эпоха обучения 5/10, weights: [-1.5, 1.75], bias: 0.75\n",
      "Эпоха обучения 6/10, weights: [-1.5, 1.75], bias: 0.75\n",
      "Эпоха обучения 7/10, weights: [-1.5, 1.75], bias: 0.75\n",
      "Эпоха обучения 8/10, weights: [-1.5, 1.75], bias: 0.75\n",
      "Эпоха обучения 9/10, weights: [-1.5, 1.75], bias: 0.75\n",
      "Эпоха обучения 10/10, weights: [-1.5, 1.75], bias: 0.75\n",
      "\n",
      "Тест после обучения\n",
      "Для входных данных [[1, 0], [1, 1]] предсказанные значения: [0, 1], ожидаемые/истинные значения: [0, 1]\n",
      "\n",
      "\"Прогоняем\" по-очереди каждый объект выборки через наш обученный перцептрон\n",
      "Perceptron, inputs: [1, 0], weights: [-1.5, 1.75], bias: 0.75, z: -0.75, activation: heaviside, a (output): 0\n",
      "Perceptron, inputs: [1, 1], weights: [-1.5, 1.75], bias: 0.75, z: 1.0, activation: heaviside, a (output): 1\n"
     ]
    }
   ],
   "source": [
    "# Входные данные и целевая метка (ожидаемый результат)\n",
    "X = [[1, 0], [1, 1]]  # выборка объектов (два объекта в выборке каждый с двумя признаками)\n",
    "y = [0, 1]  # объект x = [1, 0] класса 0, объект x = [1, 1] класса 1\n",
    "\n",
    "# Объявляем и инициализируем объект класса Perceptron\n",
    "perceptron = Perceptron(weights=[-0.5, -1.25], bias=1.75)\n",
    "print(perceptron)\n",
    "\n",
    "# Предсказания до обучения\n",
    "print('\\nТест до обучения')\n",
    "predictions = perceptron(X)\n",
    "print(f'Для входных данных {X} предсказанные значения: {predictions}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "print(f'\\nПроцесс обучения из {epochs} эпох')\n",
    "# Обучение (процесс подбора/изменения весов и смещения для нахождения решения задачи)\n",
    "for epoch in range(epochs):\n",
    "    for x, y_true in zip(X, y):    \n",
    "        # Прогон каждого отдельного одного объекта из выборки через перцептрон\n",
    "        prediction = perceptron.forward(x)\n",
    "        \n",
    "        # Вычисление ошибки\n",
    "        error = y_true - prediction\n",
    "        \n",
    "        # Обновление/изменение веса и смещения на основе ошибки\n",
    "        perceptron.update(error, x)\n",
    "    \n",
    "    # Отладочная информация\n",
    "    rounded_weights = [round(weight, 2) for weight in perceptron.weights]  # округляем веса до двух знаков после запятой для удобочитаемости\n",
    "    rounded_bias = round(perceptron.bias, 2)  # округляем смещение до двух знаков после запятой для удобочитаемости\n",
    "    print(f'Эпоха обучения {epoch + 1}/{epochs}, weights: {rounded_weights}, bias: {rounded_bias}')\n",
    "\n",
    "# Предсказание на обучающем примере\n",
    "print('\\nТест после обучения')\n",
    "predictions = perceptron(X)\n",
    "print(f'Для входных данных {X} предсказанные значения: {predictions}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "print('\\n\"Прогоняем\" по-очереди каждый объект выборки через наш обученный перцептрон')\n",
    "for x in X:\n",
    "    perceptron.forward(x)\n",
    "    print(perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "Возможно пока еще не очень понятно зачем все эти абстракции в виде классов, объектов. Кода меньше не стало, процесс обучения в целом не отличается. Какие преимущества? Просто мы пока не усложняли нашу задачу, поэтому и преимущества перехода к ООП пока могут быть не столь очевидны. Но давайте сделаем еще один довольно важный шаг и перенесем весь алгоритм обучения также в наш класс. Ведь обучение тоже напрямую относится к нашему перцептрону. Именно поэтому я и назвал главу \"Почти Перцептрон\". После реализации процесса обучения в самом классе можно сказать что у нас уже полноценный Перцептрон. Это разделение на почти перцептрон и полноценный перцептрон довольно условное. В целом нет какого-то правила что считать полноценным, а что неполноценным перцептроном. Да и в целом многие понятия довольно абстракты и условны. Я сделал такое разделение просто для постепенного продвижения от простого к более сложному. И в дальнейшем, например, мы вообще уберем метод обучения из класса нейрона на основе которого будем строить нейронную сеть, потому что метод обучения будет принадлежать такому классу как нейронная сеть а не каждому объекту нейрона в этой сети. Да и в целом мы несколько уйдем от такого понятия как нейрон. Такой класс нам не нужен будет в том виде в котором мы его реализуем сейчас. Потому что все вычисления будут происходить на уровне таких понятий как \"слой нейронной сети\". Но обо всем по-порядку. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "## 3. Перцептрон"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "Перенесем в наш класс метод для обучения перцептрона и решим уже наконец вполне конкретную задачу которая называется \"Логическое И\" (AND)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс для Перцептрона\n",
    "class Perceptron:\n",
    "    # Встроенный метод для инициализации объекта\n",
    "    def __init__(self, weights, bias=None):\n",
    "        self.inputs = None                  # входные значения (набор признкаков одного объекта x из выборки X)\n",
    "        self.weights = weights              # веса\n",
    "        self.bias = bias                    # смещение\n",
    "        self.z = None                       # взвешенная сумма входов + смещение (вычисляется позже в методе forward)\n",
    "        self.activation = self.heaviside    # функция активации\n",
    "        self.a = None                       # результат применения активационной функции (вычисляется позже в методе forward)\n",
    "    \n",
    "    # Метод для активации (пороговая функция активации)\n",
    "    def heaviside(self, z):\n",
    "        return 0 if z < 0.5 else 1\n",
    "\n",
    "    # Метод для подачи/\"прогона\" данных в/через перцептрон, вычисления z и активации (выхода/ответа)\n",
    "    def forward(self, x):\n",
    "        # Сохраняем поданные в перцептрон входные данные в переменной-атрибуте объекта\n",
    "        self.inputs = x\n",
    "        # Рассчитываем взвешенную сумму (z)\n",
    "        self.z = sum(xi * wi for xi, wi in zip(self.inputs, self.weights)) + (self.bias if self.bias is not None else 0)\n",
    "        # Применяем функцию активации к z\n",
    "        self.a = self.activation(self.z)\n",
    "        return self.a  # возвращаем результат активации (выход/ответ перцептрона output)\n",
    "    \n",
    "        # Метод для обновления/изменения весов и смещения на основе ошибки\n",
    "    def update(self, error, learning_rate):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] += learning_rate * error * self.inputs[i]\n",
    "        self.bias += learning_rate * error\n",
    "\n",
    "    # Метод для обучения\n",
    "    def fit(self, X, y, epochs, learning_rate):\n",
    "        print(f'\\nПроцесс обучения из {epochs} эпох')\n",
    "        for epoch in range(epochs):\n",
    "            for x, y_true in zip(X, y):    \n",
    "                # Прогон каждого отдельного одного объекта из выборки и получение результата\n",
    "                prediction = self.forward(x)\n",
    "                \n",
    "                # Вычисление ошибки\n",
    "                error = y_true - prediction\n",
    "                \n",
    "                # Обновление/изменение веса и смещения на основе ошибки\n",
    "                self.update(error, learning_rate)\n",
    "            \n",
    "            # Отладочная информация\n",
    "            rounded_weights = [round(weight, 2) for weight in self.weights]  # округляем веса до двух знаков после запятой для удобочитаемости\n",
    "            rounded_bias = round(self.bias, 2)  # округляем смещение до двух знаков после запятой для удобочитаемости\n",
    "            print(f'Эпоха обучения {epoch + 1}/{epochs}, weights: {rounded_weights}, bias: {rounded_bias}')\n",
    "\n",
    "    # Встроенный метод для вызова объекта как функции\n",
    "    def __call__(self, X):\n",
    "        return [self.forward(x) for x in X]\n",
    "\n",
    "    # Метод для получения предсказаний по всей выборке\n",
    "    def predict(self, X):\n",
    "        return self.__call__(X)\n",
    "    \n",
    "    # Встроенный метод для строкового представления объекта\n",
    "    def __str__(self):\n",
    "        # self.forward(self.inputs) if self.inputs is not None else ...  # рассчитываем актуальные значения z и a\n",
    "        return f'Perceptron, inputs: {self.inputs}, weights: {self.weights}, bias: {self.bias}, z: {self.z}, ' \\\n",
    "               f'activation: {self.activation.__name__}, a (output): {self.a}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "### 3.1 Логическое И (AND)\n",
    "\n",
    "Что такое \"Логическое И\"? Возможно объяснение, что это такое тут не требуется, так как с этого начинается практический любой нормальный курс по программированию, но все же еще раз вспомним что это такое и дадим пояснения в контексте нейронных сетей.\n",
    "Задача \"Логическое И\" (AND) заключается в создании логической функции, которая возвращает 1 (истина), только если оба входных значения равны 1. В остальных случаях функция возвращает 0 (ложь).\n",
    "\n",
    "Таблица истинности для операции логического И:\n",
    "| Вход A | Вход B | Выход (A AND B) |\n",
    "|--------|--------|-----------------|\n",
    "|   0    |   0    |        0        |\n",
    "|   0    |   1    |        0        |\n",
    "|   1    |   0    |        0        |\n",
    "|   1    |   1    |        1        |\n",
    "\n",
    "В контексте нейронных сетей можно сказать, что, другими словами, мы имеем четыре объекта в нашей выборке. У каждого объекта по два признака (Вход A и Вход B). И каждый объект отнесен к одному из двух классов (Выход). Задача состоит в том чтобы обучить наш перцептрон так, чтобы подавая в него каждый из объектов (каждый набор признаков объекта) наш перцептрон его бы относил к правильному классу. Возможно ли научить этому перцептрон?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron, inputs: None, weights: [-0.5, -1.25], bias: 1.75, z: None, activation: heaviside, a (output): None\n",
      "\n",
      "Тест до обучения\n",
      "Для входных данных [[0, 0], [0, 1], [1, 0], [1, 1]] предсказанные значения: [1, 1, 1, 0], ожидаемые/истинные значения: [0, 0, 0, 1]\n",
      "\n",
      "Процесс обучения из 10 эпох\n",
      "Эпоха обучения 1/10, weights: [0.5, -0.25], bias: 1.75\n",
      "Эпоха обучения 2/10, weights: [1.5, -0.25], bias: 0.75\n",
      "Эпоха обучения 3/10, weights: [1.5, 0.75], bias: -0.25\n",
      "Эпоха обучения 4/10, weights: [2.5, 0.75], bias: -0.25\n",
      "Эпоха обучения 5/10, weights: [2.5, 0.75], bias: -1.25\n",
      "Эпоха обучения 6/10, weights: [2.5, 1.75], bias: -1.25\n",
      "Эпоха обучения 7/10, weights: [2.5, 0.75], bias: -2.25\n",
      "Эпоха обучения 8/10, weights: [2.5, 0.75], bias: -2.25\n",
      "Эпоха обучения 9/10, weights: [2.5, 0.75], bias: -2.25\n",
      "Эпоха обучения 10/10, weights: [2.5, 0.75], bias: -2.25\n",
      "\n",
      "Тест после обучения\n",
      "Для входных данных [[0, 0], [0, 1], [1, 0], [1, 1]] предсказанные значения: [0, 0, 0, 1], ожидаемые/истинные значения: [0, 0, 0, 1]\n",
      "\n",
      "\"Прогоняем\" по-очереди каждый объект выборки через наш обученный перцептрон\n",
      "Perceptron, inputs: [0, 0], weights: [2.5, 0.75], bias: -2.25, z: -2.25, activation: heaviside, a (output): 0\n",
      "Perceptron, inputs: [0, 1], weights: [2.5, 0.75], bias: -2.25, z: -1.5, activation: heaviside, a (output): 0\n",
      "Perceptron, inputs: [1, 0], weights: [2.5, 0.75], bias: -2.25, z: 0.25, activation: heaviside, a (output): 0\n",
      "Perceptron, inputs: [1, 1], weights: [2.5, 0.75], bias: -2.25, z: 1.0, activation: heaviside, a (output): 1\n"
     ]
    }
   ],
   "source": [
    "# Задача AND\n",
    "# Входные данные и целевая метка (ожидаемый результат)\n",
    "X = [[0, 0], [0, 1], [1, 0], [1, 1]]  # выборка объектов (четыре объекта в выборке каждый с двумя признаками)\n",
    "y = [0, 0, 0, 1]  # объекты c признаками [0, 0], [0, 1] и [1, 0] принадлежат классу 0, объект с признаком [1, 1] к классу 1\n",
    "\n",
    "# Объявляем и инициализируем объект класса Perceptron\n",
    "perceptron = Perceptron(weights=[-0.5, -1.25], bias=1.75)\n",
    "print(perceptron)\n",
    "\n",
    "# Предсказания до обучения\n",
    "print('\\nТест до обучения')\n",
    "predictions = perceptron(X)\n",
    "print(f'Для входных данных {X} предсказанные значения: {predictions}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "# Обучаем перцептрон\n",
    "perceptron.fit(X, y, epochs=10, learning_rate=1)\n",
    "\n",
    "# Предсказание на обучающем примере\n",
    "print('\\nТест после обучения')\n",
    "predictions = perceptron(X)\n",
    "print(f'Для входных данных {X} предсказанные значения: {predictions}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "print('\\n\"Прогоняем\" по-очереди каждый объект выборки через наш обученный перцептрон')\n",
    "for x in X:\n",
    "    perceptron.forward(x)\n",
    "    print(perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "Мы видим, что наш перцептрон научисля решать задачу \"Логическое И\". Касательно кода можно заметить, что мы перенесли метод обучения перцептрона непосредственно в класс Perceptron, добавили переменную `learning_rate` и так как у нас каждый набор признаков записывается в методе `forward` в переменную `self.inputs` то мы можем в метод `update` не передавать текущий `x` а просто брать эти значения из `self.inputs`. Можно было так же сделать и с learning_rate, но в будущем мы все равно перенесем этот параметр в другой объект класса Optimaizer, поэтому пока оставим так как есть. Тут хотелось бы подробнее остановиться на описании параметра learning_rate.\n",
    "\n",
    "**Learning rate** (коэффициент обучения) — это гиперпараметр, который используется в процессе обучения моделей машинного обучения и определяет размер шага, на который обновляются параметры модели (например, веса в нейронной сети) при каждом шаге оптимизации/обучения.\n",
    "\n",
    "Основные моменты:\n",
    "\n",
    "- **Обновление параметров:** Во время обучения модели (например, нейронной сети) параметры, такие как веса, обновляются с каждым шагом оптимизации для минимизации ошибки (функции потерь). Learning rate определяет, насколько сильно изменятся параметры на каждом шаге.\n",
    "- **Влияние значения:**\n",
    "   - **Маленький learning rate:** Обновления параметров происходят медленно, что может привести к длительному обучению и застреванию в локальных минимумах.\n",
    "   - **Большой learning rate:** Обновления происходят слишком резко, что может привести к неустойчивому обучению, и модель может не достичь оптимального решения.\n",
    "- **Оптимизация:** Подбор подходящего значения learning rate — важная часть настройки модели. Иногда используются стратегии, такие как адаптивные методы (например, Adam), которые автоматически изменяют learning rate в процессе обучения.\n",
    "\n",
    "Если learning rate = 0.01, это означает, что на каждом шаге оптимизации параметры изменяются на 1% от рассчитанного значения градиента функции потерь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "### 3.2 Логическое ИЛИ (OR)\n",
    "\n",
    "Перед тем как сделать следующий шаг давайте рассмотрим еще парочку задач. Первая из них это \"Логичексое ИЛИ\" (OR). Тут принцип абсолютно такой же как и в прошлой задаче за исключением того что \"Логическое ИЛИ\" возвращает истину (1), если хотя бы один из входов истинен. Если оба входа ложны (0), то результатом будет ложь (0).\n",
    "\n",
    "Таблица истинности для операции логического ИЛИ:\n",
    "| Вход A | Вход B | Выход (A AND B) |\n",
    "|--------|--------|-----------------|\n",
    "|   0    |   0    |        0        |\n",
    "|   0    |   1    |        1        |\n",
    "|   1    |   0    |        1        |\n",
    "|   1    |   1    |        1        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron, inputs: None, weights: [-0.5, -1.25], bias: 1.75, z: None, activation: heaviside, a (output): None\n",
      "\n",
      "Тест до обучения\n",
      "Для входных данных [[0, 0], [0, 1], [1, 0], [1, 1]] предсказанные значения: [1, 1, 1, 0], ожидаемые/истинные значения: [0, 1, 1, 1]\n",
      "\n",
      "Процесс обучения из 10 эпох\n",
      "Эпоха обучения 1/10, weights: [-0.5, -0.25], bias: 1.75\n",
      "Эпоха обучения 2/10, weights: [0.5, -0.25], bias: 1.75\n",
      "Эпоха обучения 3/10, weights: [0.5, -0.25], bias: 0.75\n",
      "Эпоха обучения 4/10, weights: [0.5, 0.75], bias: 0.75\n",
      "Эпоха обучения 5/10, weights: [1.5, 0.75], bias: 0.75\n",
      "Эпоха обучения 6/10, weights: [1.5, 0.75], bias: -0.25\n",
      "Эпоха обучения 7/10, weights: [1.5, 0.75], bias: -0.25\n",
      "Эпоха обучения 8/10, weights: [1.5, 0.75], bias: -0.25\n",
      "Эпоха обучения 9/10, weights: [1.5, 0.75], bias: -0.25\n",
      "Эпоха обучения 10/10, weights: [1.5, 0.75], bias: -0.25\n",
      "\n",
      "Тест после обучения\n",
      "Для входных данных [[0, 0], [0, 1], [1, 0], [1, 1]] предсказанные значения: [0, 1, 1, 1], ожидаемые/истинные значения: [0, 1, 1, 1]\n",
      "\n",
      "\"Прогоняем\" по-очереди каждый объект выборки через наш обученный перцептрон\n",
      "Perceptron, inputs: [0, 0], weights: [1.5, 0.75], bias: -0.25, z: -0.25, activation: heaviside, a (output): 0\n",
      "Perceptron, inputs: [0, 1], weights: [1.5, 0.75], bias: -0.25, z: 0.5, activation: heaviside, a (output): 1\n",
      "Perceptron, inputs: [1, 0], weights: [1.5, 0.75], bias: -0.25, z: 1.25, activation: heaviside, a (output): 1\n",
      "Perceptron, inputs: [1, 1], weights: [1.5, 0.75], bias: -0.25, z: 2.0, activation: heaviside, a (output): 1\n"
     ]
    }
   ],
   "source": [
    "# Задача OR\n",
    "# Входные данные и целевая метка (ожидаемый результат)\n",
    "X = [[0, 0], [0, 1], [1, 0], [1, 1]]  # выборка объектов (четыре объекта в выборке каждый с двумя признаками)\n",
    "y = [0, 1, 1, 1]  # объект c признаком [0, 0] принадлежат классу 0, объекты с признаками [0, 1], [1, 0] и [1, 1] к классу 1\n",
    "\n",
    "# Объявляем и инициализируем объект класса Perceptron\n",
    "perceptron = Perceptron(weights=[-0.5, -1.25], bias=1.75)\n",
    "print(perceptron)\n",
    "\n",
    "# Предсказания до обучения\n",
    "print('\\nТест до обучения')\n",
    "predictions = perceptron(X)\n",
    "print(f'Для входных данных {X} предсказанные значения: {predictions}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "# Обучаем перцептрон\n",
    "perceptron.fit(X, y, epochs=10, learning_rate=1)\n",
    "\n",
    "# Предсказание на обучающем примере\n",
    "print('\\nТест после обучения')\n",
    "predictions = perceptron(X)\n",
    "print(f'Для входных данных {X} предсказанные значения: {predictions}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "print('\\n\"Прогоняем\" по-очереди каждый объект выборки через наш обученный перцептрон')\n",
    "for x in X:\n",
    "    perceptron.forward(x)\n",
    "    print(perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "Как видим, наш перцептрон вполне способен решить задачу логического ИЛИ. И тут мы подходим к интересному моменту. А именно, вернемся к началу. Как можно узнать из различных источников, перцептрон был изобретён в 1957 году Фрэнком Розенблаттом. Это была одна из первых моделей искусственного интеллекта. Вот краткая хронология событий, связанных с перцептроном:\n",
    "\n",
    "**Изобретение и начальные успехи (1957):**\n",
    "- Фрэнк Розенблатт разработал перцептрон, который являлся первой моделью нейрона, способной к обучению.\n",
    "- В 1958 году на перцептроне была проведена демонстрация на IBM 704, вызвавшая значительный интерес в научных кругах и прессе.\n",
    "- В начале 1960-х годов Розенблатт получил финансирование от ВМС США для разработки аппаратной реализации перцептрона, называемой Mark I Perceptron.\n",
    "\n",
    "**Критика и ограничения (1969):**\n",
    "- В 1969 году Марвин Минский и Сеймур Пейперт опубликовали книгу \"Perceptrons\", в которой описали ограничения перцептрона, такие как невозможность решения задачи XOR и других нелинейно разделимых задач.\n",
    "- Их работа показала, что перцептрон не может обрабатывать нелинейные зависимости, что привело к значительному снижению интереса к исследованиям в области нейронных сетей на несколько лет.\n",
    "\n",
    "История также говорит нам, что Фрэнк Розенблатт умер в 1971 году в возрасте 43 лет. Хотя его смерть не была основной причиной остановки развития нейронных сетей, она совпала с рядом других факторов, приведших к периоду, известному как \"AI зима\". Это был период снижения интереса и финансирования в области искусственного интеллекта, вызванный завышенными ожиданиями, техническими ограничениями и критическими публикациями. Кстати, стоит отметить, что Розенблатт не утверждал, что перцептрон может решить любые задачи, но сеть из нескольких перцептронов вполне способна решить задачу XOR. Однако, как говорится, ~~AI~~ зима близко.\n",
    "\n",
    "Еще раз о AND, OR, XOR.\n",
    "Если нарисовать на графике четыре точки `[[0, 0], [0, 1], [1, 0], [1, 1]]` задачи логического И и просто посмотреть на этот график, то можно легко понять, как эти точки разделить одной прямой линией так, чтобы по одну сторону линии оказались точки одного класса, а по другую — точки другого класса. То же самое можно сделать и для задачи логического ИЛИ. Однако для задачи исключающего ИЛИ (XOR) такую разделительную линию уже невозможно провести. Один перцептрон не способен решить такую задачу, то есть не может правильно классифицировать все точки. Давайте проверим это."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "### 3.3 Исключающее ИЛИ (XOR) и однослойный перцептрон\n",
    "\n",
    "XOR (Exclusive OR) - это логическая операция, которая выдает значение истина (1) тогда и только тогда, когда один из входов равен истине (1), а другой равен лжи (0). В отличие от логических операций AND и OR, задача XOR не является линейно разделимой, что делает ее интересной и сложной для ранних нейронных сетей, таких как однослойные перцептроны.\n",
    "\n",
    "Таблица истинности для операции исключающего ИЛИ:\n",
    "| Вход A | Вход B | Выход (A AND B) |\n",
    "|--------|--------|-----------------|\n",
    "|   0    |   0    |        0        |\n",
    "|   0    |   1    |        1        |\n",
    "|   1    |   0    |        1        |\n",
    "|   1    |   1    |        0        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron, inputs: None, weights: [-0.5, -1.25], bias: 1.75, z: None, activation: heaviside, a (output): None\n",
      "\n",
      "Тест до обучения\n",
      "Для входных данных [[0, 0], [0, 1], [1, 0], [1, 1]] предсказанные значения: [1, 1, 1, 0], ожидаемые/истинные значения: [0, 1, 1, 0]\n",
      "\n",
      "Процесс обучения из 10 эпох\n",
      "Эпоха обучения 1/10, weights: [-0.5, -1.0], bias: 1.75\n",
      "Эпоха обучения 2/10, weights: [-0.5, -1.0], bias: 1.5\n",
      "Эпоха обучения 3/10, weights: [-0.5, -0.75], bias: 1.5\n",
      "Эпоха обучения 4/10, weights: [-0.5, -0.75], bias: 1.25\n",
      "Эпоха обучения 5/10, weights: [-0.5, -0.5], bias: 1.25\n",
      "Эпоха обучения 6/10, weights: [-0.5, -0.5], bias: 1.0\n",
      "Эпоха обучения 7/10, weights: [-0.5, -0.25], bias: 1.0\n",
      "Эпоха обучения 8/10, weights: [-0.5, -0.5], bias: 0.75\n",
      "Эпоха обучения 9/10, weights: [-0.5, -0.5], bias: 0.75\n",
      "Эпоха обучения 10/10, weights: [-0.5, -0.5], bias: 0.75\n",
      "\n",
      "Тест после обучения\n",
      "Для входных данных [[0, 0], [0, 1], [1, 0], [1, 1]] предсказанные значения: [1, 0, 0, 0], ожидаемые/истинные значения: [0, 1, 1, 0]\n",
      "\n",
      "\"Прогоняем\" по-очереди каждый объект выборки через наш обученный перцептрон\n",
      "Perceptron, inputs: [0, 0], weights: [-0.5, -0.5], bias: 0.75, z: 0.75, activation: heaviside, a (output): 1\n",
      "Perceptron, inputs: [0, 1], weights: [-0.5, -0.5], bias: 0.75, z: 0.25, activation: heaviside, a (output): 0\n",
      "Perceptron, inputs: [1, 0], weights: [-0.5, -0.5], bias: 0.75, z: 0.25, activation: heaviside, a (output): 0\n",
      "Perceptron, inputs: [1, 1], weights: [-0.5, -0.5], bias: 0.75, z: -0.25, activation: heaviside, a (output): 0\n"
     ]
    }
   ],
   "source": [
    "# Задача XOR\n",
    "# Входные данные и целевая метка (ожидаемый результат)\n",
    "X = [[0, 0], [0, 1], [1, 0], [1, 1]]  # выборка объектов (четыре объекта в выборке каждый с двумя признаками)\n",
    "y = [0, 1, 1, 0]  # объекты c признаками [0, 0] и [1, 1] принадлежат классу 0, объекты с признаками [0, 1] и [1, 0] к классу 1\n",
    "\n",
    "# Объявляем и инициализируем объект класса Perceptron\n",
    "perceptron = Perceptron(weights=[-0.5, -1.25], bias=1.75)\n",
    "print(perceptron)\n",
    "\n",
    "# Предсказания до обучения\n",
    "print('\\nТест до обучения')\n",
    "predictions = perceptron(X)\n",
    "print(f'Для входных данных {X} предсказанные значения: {predictions}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "# Обучаем перцептрон\n",
    "perceptron.fit(X, y, epochs=10, learning_rate=0.25)\n",
    "\n",
    "# Предсказание на обучающем примере\n",
    "print('\\nТест после обучения')\n",
    "predictions = perceptron(X)\n",
    "print(f'Для входных данных {X} предсказанные значения: {predictions}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "print('\\n\"Прогоняем\" по-очереди каждый объект выборки через наш обученный перцептрон')\n",
    "for x in X:\n",
    "    perceptron.forward(x)\n",
    "    print(perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "Сколько бы мы не подбирали/обучали веса мы не решим эту задачу одним перцептроном (однослойным перцептроном). Но эта задача вполне себе решается многослойным перцептроном. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "## 4. Нейрон\n",
    "\n",
    "Следующим шагом было бы логично реализовать некий класс для слоя и класс этой самой многослойной сети из перцептронов и убедится, что задача XOR да и многие другие линейно неразделимые объекты можно правльно классифицировать с помощью MLP (многослойного перцептрона). \n",
    "\n",
    "Но обратимся еще раз к Википедии:\n",
    "\n",
    "_\"В настоящее время в литературе под термином «перцептрон» понимается чаще всего однослойный перцептрон (англ. Single-layer perceptron), причём, существует распространённое заблуждение, что именно этот простейший тип моделей предложил Розенблатт. В противоположность однослойному ставят «многослойный перцептрон» (англ. Multilayer perceptron), опять же, чаще всего подразумевая многослойный перцептрон Румельхарта, а не Розенблатта. Классический перцептрон в такой дихотомии относят к многослойным.\"_\n",
    "\n",
    "Чтобы избежать путанницы предлагаю отойти от понятия перецептрон и создать более общий класс с названием Neuron. И уже на базе этого класса можно строить разные нейроны с различными функциями активации например и получить тот же самый однослойный перцептрон. А к примеру при использовании линейной активации мы получим линейный нейрон, который работает как та же линейная регрессия.\n",
    "\n",
    "Итак, в целом, нейрон - это тоже самое, что и однослойный перцептрон. И работает и обучается точно так же. И сеть на нейронах выглядит так же. Хотя, повторюсь, понятие нейрон тоже довольно условное. Как я уже говорил в keras вообще нет такого понятия как нейрон. Там все вычисления происходят в слоях которые представлены в виде матриц и отдельно понятие нейрон никак не выделяется. Но пока мы все равно напишем класс Neuron. И тут нам нужно практически сразу разобраться и реализовать довольно много нового. А именно:\n",
    "\n",
    "1. Нам нужно перейти на использование такой библиотеки как numpy. Это библиотека для работы с массивами и матрицами написанная на C, а некоторые библиотеки для линейной алгебры, используемые внутри numpy, написаны на Фортране. Для начала мы конечно не ощутим сильного прироста производительности, но при написании класса Layer в котором будут перемножаться матрицы весов и матрицы входных сигналов прирост производительности будет очень существенным. \n",
    "2. Мы вынесем нашу функцию автивации из класса нейрон, добавим еще несколько видов функции активации с их производными и сохраним эти функции в файле activations.py. \n",
    "3. Добавим loss-функцию и ее производную.\n",
    "\n",
    "Помимо этих трех пунктов, так как у нас появились функции активации которые дифференцируемы, соответственно нам нужно разобраться с таким, достаточно важным понятием, как производная.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "### 4.1 Кратко о numpy\n",
    "\n",
    "NumPy — это библиотека для языка программирования Python, которая предоставляет поддержку многомерных массивов и матриц, а также функции для выполнения различных математических операций с ними. Она широко используется в научных вычислениях, обработке данных и машинном обучении благодаря своей эффективности и удобству работы с данными. По NumPy есть много курсов и показывать даже основную часть ввзможностей numpy в этом курсе нет возможности. Поэтому как и с ООП, буду рассказывать только о том, что буду использовать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "### 4.2 Подробнее о функциях активации и numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activations.py\n",
    "import numpy as np  # библиотека для работы с массивами и матрицами\n",
    "\n",
    "# Функция активации Sigmoid с расчетом производной\n",
    "def sigmoid(Z, derivative=False):\n",
    "    sigmoid_Z = 1 / (1 + np.exp(-Z))\n",
    "    if derivative:\n",
    "        return sigmoid_Z * (1 - sigmoid_Z)\n",
    "    return sigmoid_Z\n",
    "\n",
    "# Функция активации Tanh с расчетом производной\n",
    "def tanh(Z, derivative=False):\n",
    "    tanh_Z = np.tanh(Z)\n",
    "    if derivative:\n",
    "        return 1 - np.power(tanh_Z, 2)\n",
    "    return tanh_Z\n",
    "\n",
    "# Функция активации ReLU с расчетом производной\n",
    "def relu(Z, derivative=False):\n",
    "    if derivative:\n",
    "        return (Z > 0).astype(float)\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "# Функция активации Softplus с расчетом производной\n",
    "def softplus(Z, derivative=False):\n",
    "    if derivative:\n",
    "        return 1 / (1 + np.exp(-Z))  # производная Softplus это sigmoid\n",
    "    return np.log(1 + np.exp(Z))\n",
    "\n",
    "# Функция активации Linear (линейная функция)\n",
    "def linear(Z, derivative=False):\n",
    "    if derivative:\n",
    "        return np.ones_like(Z)\n",
    "    return Z\n",
    "\n",
    "# Функция активации Heaviside (Step Function) с расчетом производной\n",
    "def heaviside(Z, derivative=False):\n",
    "    treshold = 0.5\n",
    "    if derivative:\n",
    "        # Обратите внимание: формально производная Хевисайда не определена в точке разрыва.\n",
    "        # Для практической совместимости возвращаем массив единиц.\n",
    "        return np.ones_like(Z)\n",
    "    return np.where(Z < treshold, 0, 1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "Мы вынесли в файл activations.py несколько наиболее распространенных активационных функций. По мере необходимости будем добавлять новые функции. У всех функций указаны их производные, которые понадобятся нам при создании многослойной нейронной сети и реализации метода обратного распространения ошибки (backpropagation). Производные для таких функций, как linear и heaviside, также указаны для совместимости. Стоит отметить, что в случае linear производная равна 1 и имеет смысл в контексте нейронных сетей, тогда как для heaviside производная не определена в точке разрыва. Мы используем библиотеку numpy, которая позволяет нам передавать в функции активации не только одиночные значения, но и обрабатывать целые массивы, возвращая массивы активаций.\n",
    "\n",
    "Краткое пояснение:\n",
    "- `import numpy as np`:\n",
    "Импорт библиотеки numpy под псевдонимом np.\n",
    "- `np.exp(-Z)`:\n",
    "Функция np.exp() вычисляет экспоненту для каждого элемента массива Z. В данном случае используется для вычисления сигмоидальной функции и производной softplus.\n",
    "- `np.tanh(Z)`:\n",
    "Функция np.tanh() вычисляет гиперболический тангенс для каждого элемента массива Z. Это используется для активационной функции tanh.\n",
    "- `np.power(tanh_Z, 2)`:\n",
    "Функция np.power() возводит каждый элемент массива tanh_Z в степень 2. Это используется для вычисления производной функции tanh.\n",
    "- `np.maximum(0, Z)`:\n",
    "Функция np.maximum() возвращает максимум из двух значений для каждого элемента массива Z. В данном случае она используется для реализации функции ReLU (Rectified Linear Unit), которая возвращает 0 для отрицательных значений и само значение для положительных.\n",
    "- `np.log(1 + np.exp(Z))`:\n",
    "Функция np.log() вычисляет натуральный логарифм для каждого элемента массива 1 + np.exp(Z). Это используется для реализации функции активации softplus.\n",
    "- `np.ones_like(Z)`:\n",
    "Функция np.ones_like() создает массив из единиц той же формы, что и массив Z. Она используется для возврата единичного массива в качестве производной для функций linear и heaviside.\n",
    "- `np.where(Z < treshold, 0, 1).astype(int)`:\n",
    "Функция np.where() возвращает массив, где каждый элемент равен 0, если соответствующий элемент Z меньше порога treshold, и 1 в противном случае. Этот массив затем приводится к целочисленному типу с помощью .astype(int). Это используется для реализации функции активации Heaviside (ступенчатая функция)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# units.py\n",
    "import numpy as np\n",
    "\n",
    "# Класс для Нейрона\n",
    "class Neuron:\n",
    "    # Встроенный метод для инициализации объекта\n",
    "    def __init__(self, weights, bias=None, activation=linear):\n",
    "        self.inputs = np.nan\n",
    "        self.weights = np.array(weights)\n",
    "        self.bias = np.float64(bias) if bias is not None else None\n",
    "        self.z = None\n",
    "        self.activation = activation\n",
    "        self.a = None\n",
    "\n",
    "    # Метод для подачи/\"прогона\" данных в/через перцептрон, вычисления z и активации (выхода/ответа)\n",
    "    def forward(self, x):\n",
    "        # Сохраняем поданные в перцептрон входные данные в переменной-атрибуте объекта\n",
    "        self.inputs = x\n",
    "        # Рассчитываем взвешенную сумму (z)\n",
    "        self.z = np.dot(self.inputs, self.weights) + (self.bias if self.bias is not None else 0)\n",
    "        # Применяем функцию активации к z\n",
    "        self.a = self.activation(self.z)\n",
    "        return self.a  # возвращаем результат активации (выход/ответ перцептрона output)\n",
    "    \n",
    "        # Метод для обновления/изменения весов и смещения на основе ошибки\n",
    "    def update(self, error, learning_rate):\n",
    "        self.weights += learning_rate * error * self.inputs\n",
    "        if self.bias is not None:\n",
    "            self.bias += learning_rate * error\n",
    "\n",
    "    # Метод для обучения\n",
    "    def fit(self, X, y, epochs, learning_rate):\n",
    "        y = y.reshape(-1, 1)\n",
    "        print(f'Процесс обучения из {epochs} эпох')\n",
    "        for epoch in range(epochs):\n",
    "            for x, y_true in zip(X, y):    \n",
    "                # Прогон каждого отдельного одного объекта из выборки и получение результата\n",
    "                prediction = self.forward(x)\n",
    "                \n",
    "                # Вычисление ошибки\n",
    "                error = y_true - prediction\n",
    "                \n",
    "                # Обновление/изменение веса и смещения на основе ошибки\n",
    "                self.update(error, learning_rate)\n",
    "            \n",
    "            # Отладочная информация\n",
    "            print(f'Эпоха обучения {epoch + 1}/{epochs}, weights: {self.weights}, bias: {np.float64(self.bias)}')\n",
    "\n",
    "    # Встроенный метод для вызова объекта как функции\n",
    "    def __call__(self, X):\n",
    "        return np.array([self.forward(x) for x in X])\n",
    "\n",
    "    # Метод для получения предсказаний по всей выборке\n",
    "    def predict(self, X):\n",
    "        return self.__call__(X)\n",
    "    \n",
    "    # Встроенный метод для строкового представления объекта\n",
    "    def __str__(self):\n",
    "        # self.forward(self.inputs) if self.inputs is not None else ...  # рассчитываем актуальные значения z и a\n",
    "        return f'Neuron, inputs: {self.inputs}, weights: {self.weights}, bias: {np.float64(self.bias)}, z: {np.float64(self.z)}, ' \\\n",
    "               f'activation: {self.activation.__name__}, a (output): {np.float64(self.a)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "Краткое пояснение:\n",
    "- `self.inputs = np.nan` - `np.nan` представляет собой специальное значение \"Not a Number\" (не число), которое используется для инициализации переменных, когда у нас еще нет данных. В данном случае это начальное значение для входных данных `self.inputs`.\n",
    "- `self.weights = np.array(weights)` - `np.array()` создает массив numpy на основе переданного списка `[weights]`. Это нужно для работы с весами нейрона в виде массива, что позволяет эффективно выполнять линейные алгебраические операции.\n",
    "- `self.bias = np.float64(bias) if bias is not None else None` - `np.float64()` преобразует значение `bias` в число с плавающей запятой двойной точности (64-битное). Если `bias` не указан, устанавливается значение `None`.\n",
    "- `self.z = np.dot(self.inputs, self.weights) + (self.bias if self.bias is not None else 0)` - `np.dot()` выполняет скалярное произведение двух массивов. Здесь оно используется для вычисления взвешенной суммы входов `self.inputs` и весов `self.weights`.\n",
    "- `self.weights += learning_rate * error * self.inputs` - здесь `self.weights` обновляются с использованием правила градиентного спуска. В данном случае `learning_rate`, `error`, и `self.inputs` — это скалярные или векторные величины, и numpy обеспечивает их корректное поэлементное умножение и сложение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процесс обучения из 10 эпох\n",
      "Эпоха обучения 1/10, weights: [-0.5 -1. ], bias: 1.75\n",
      "Эпоха обучения 2/10, weights: [-0.5 -1. ], bias: 1.5\n",
      "Эпоха обучения 3/10, weights: [-0.5  -0.75], bias: 1.5\n",
      "Эпоха обучения 4/10, weights: [-0.5  -0.75], bias: 1.25\n",
      "Эпоха обучения 5/10, weights: [-0.5 -0.5], bias: 1.25\n",
      "Эпоха обучения 6/10, weights: [-0.5 -0.5], bias: 1.0\n",
      "Эпоха обучения 7/10, weights: [-0.5  -0.25], bias: 1.0\n",
      "Эпоха обучения 8/10, weights: [-0.5 -0.5], bias: 0.75\n",
      "Эпоха обучения 9/10, weights: [-0.5 -0.5], bias: 0.75\n",
      "Эпоха обучения 10/10, weights: [-0.5 -0.5], bias: 0.75\n",
      "\n",
      "Предсказанные значения: [1 0 0 0], ожидаемые/истинные значения: [0 1 1 0]\n",
      "\n",
      "\"Прогоняем\" по-очереди каждый объект выборки через наш обученный перцептрон\n",
      "Neuron, inputs: [0 0], weights: [-0.5 -0.5], bias: 0.75, z: 0.75, activation: heaviside, a (output): 1.0\n",
      "Neuron, inputs: [0 1], weights: [-0.5 -0.5], bias: 0.75, z: 0.25, activation: heaviside, a (output): 0.0\n",
      "Neuron, inputs: [1 0], weights: [-0.5 -0.5], bias: 0.75, z: 0.25, activation: heaviside, a (output): 0.0\n",
      "Neuron, inputs: [1 1], weights: [-0.5 -0.5], bias: 0.75, z: -0.25, activation: heaviside, a (output): 0.0\n"
     ]
    }
   ],
   "source": [
    "# Задача XOR\n",
    "# Входные данные и целевая метка (ожидаемый результат)\n",
    "X = np.array([[0, 0], \n",
    "              [0, 1], \n",
    "              [1, 0], \n",
    "              [1, 1]])  # выборка объектов (четыре объекта в выборке каждый с двумя признаками)\n",
    "y = np.array([0, 1, 1, 0])  # объекты c признаками [0, 0] и [1, 1] принадлежат классу 0, объекты с признаками [0, 1] и [1, 0] к классу 1\n",
    "\n",
    "# Объявляем и инициализируем объект класса Neuron с пороговой функцией активации\n",
    "perceptron = Neuron(weights=[-0.5, -1.25], bias=1.75, activation=heaviside)\n",
    "\n",
    "# Обучаем перцептрон\n",
    "perceptron.fit(X, y, epochs=10, learning_rate=0.25)\n",
    "\n",
    "# Предсказание на обучающем примере\n",
    "predictions = perceptron(X)\n",
    "print(f'\\nПредсказанные значения: {predictions.flatten()}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "print('\\n\"Прогоняем\" по-очереди каждый объект выборки через наш обученный перцептрон')\n",
    "for x in X:\n",
    "    perceptron.forward(x)\n",
    "    print(perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "- `predictions.flatten()` - метод `flatten()` возвращает копию массива, преобразованного в одномерный массив. Используем просто для удобочитаемости."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "### 4.3 Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses.py\n",
    "import numpy as np\n",
    "\n",
    "# Классы для функции потерь\n",
    "class LossFunction:\n",
    "    def evaluate_error(self, y, predictions):\n",
    "        raise NotImplementedError('This method should be overridden by subclasses')\n",
    "    \n",
    "    def loss_derivative(self, error):\n",
    "        raise NotImplementedError('This method should be overridden by subclasses')\n",
    "\n",
    "    def evaluate_loss(self, y, predictions):\n",
    "        raise NotImplementedError('This method should be overridden by subclasses')\n",
    "\n",
    "class MAE(LossFunction):\n",
    "    def evaluate_error(self, y, predictions):\n",
    "        return (predictions - y) / len(y)\n",
    "    \n",
    "    def loss_derivative(self, error):\n",
    "        return np.sign(error)\n",
    "    \n",
    "    def evaluate_loss(self, y, predictions):\n",
    "        return np.mean(np.abs(predictions - y))\n",
    "    \n",
    "    def __str__(self):\n",
    "        return '\"Mean Absolute Error\"'\n",
    "    \n",
    "class MSE(LossFunction):\n",
    "    def evaluate_error(self, y, predictions):\n",
    "        return (predictions - y) / len(y)\n",
    "    \n",
    "    def loss_derivative(self, error):\n",
    "        return 2 * error\n",
    "    \n",
    "    def evaluate_loss(self, y, predictions):\n",
    "        return np.mean(np.square(predictions - y))\n",
    "\n",
    "    def __str__(self):\n",
    "        return '\"Mean Squared Error\"'\n",
    "\n",
    "class CE(LossFunction):\n",
    "    def evaluate_error(self, y, predictions):\n",
    "        return predictions - y\n",
    "    \n",
    "    def loss_derivative(self, error):\n",
    "        return error\n",
    "\n",
    "    def evaluate_loss(self, y, predictions):\n",
    "        epsilon = 1e-8\n",
    "        return -np.mean(np.sum(y * np.log(predictions + epsilon), axis=1))\n",
    "    \n",
    "    def __str__(self):\n",
    "        return '\"Categorical Crossentropy\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "**Пояснение к коду**\n",
    "\n",
    "В этом коде определены несколько классов для реализации различных функций потерь (Loss Functions), которые используются для оценки качества предсказаний моделей машинного обучения. Функции потерь измеряют разницу между предсказанными значениями модели и реальными значениями. Ниже я объясню, как работают эти классы и какие основные методы реализованы. Мы добавим сразу три функции потерь что бы не возвращаться уже к этому файлу, но будем использовать пока только MSE.\n",
    "\n",
    "1. Базовый класс `LossFunction`: Этот класс является абстрактным и определяет интерфейс для всех функций потерь, которые будут реализованы в подклассах. В нем определены три метода:\n",
    "- `evaluate_error(self, y, predictions)`: Вычисляет ошибку между реальными значениями `y` и предсказаниями модели `predictions`.\n",
    "- `loss_derivative(self, error)`: Вычисляет производную функции потерь по ошибке, что необходимо для методов оптимизации, таких как градиентный спуск.\n",
    "- `evaluate_loss(self, y, predictions)`: Вычисляет значение функции потерь, основываясь на реальных значениях `y` и предсказаниях модели `predictions`.\n",
    "Эти методы объявлены, но не реализованы, так как они должны быть переопределены в подклассах, которые будут определять конкретные функции потерь.\n",
    "2. Класс `MAE` (Mean Absolute Error): Этот класс реализует функцию потерь, известную как средняя абсолютная ошибка.\n",
    "- `evaluate_error(self, y, predictions)`: Возвращает вектор ошибок, деленный на количество элементов, чтобы обеспечить правильный масштаб ошибок.\n",
    "- `loss_derivative(self, error)`: Возвращает знак ошибки (положительный или отрицательный), что используется для обновления весов модели.\n",
    "- `evaluate_loss(self, y, predictions)`: Вычисляет среднее абсолютное значение ошибки между реальными значениями и предсказаниями.\n",
    "3. Класс `MSE` (Mean Squared Error): Этот класс реализует функцию потерь, известную как среднеквадратичная ошибка.\n",
    "- `evaluate_error(self, y, predictions)`: Подобно `MAE`, возвращает вектор ошибок, деленный на количество элементов.\n",
    "- `loss_derivative(self, error)`: Возвращает удвоенное значение ошибки, так как производная квадрата функции равна удвоенному значению.\n",
    "- `evaluate_loss(self, y, predictions)`: Вычисляет среднее значение квадрата разностей между реальными значениями и предсказаниями.\n",
    "4. Класс `CE` (Categorical Crossentropy): Этот класс реализует функцию потерь для задач классификации, известную как категориальная кросс-энтропия.\n",
    "- `evaluate_error(self, y, predictions)`: Вычисляет разницу между предсказаниями и реальными значениями, что в данном случае является ошибкой.\n",
    "- `loss_derivative(self, error)`: Возвращает ошибку, так как производная кросс-энтропии по логитам равна ошибке.\n",
    "- `evaluate_loss(self, y, predictions)`: Вычисляет среднюю кросс-энтропию для всех предсказаний. Для предотвращения вычислительных ошибок добавляется небольшое значение `epsilon`.\n",
    "\n",
    "**Пояснение понятий** `loss` и `loss function`\n",
    "\n",
    "- **Loss (Ошибка):** Это мера того, насколько сильно предсказания модели отличаются от реальных значений. Величина ошибки показывает, насколько плохо модель предсказывает результат.\n",
    "- **Loss Function (Функция потерь):** Это функция, которая принимает реальные значения и предсказанные значения, а затем возвращает значение ошибки. Она используется для обучения модели: функция потерь минимизируется в процессе оптимизации, что позволяет модели улучшать свои предсказания. Разные функции потерь используются в зависимости от задачи (регрессия, классификация и т.д.) и особенностей данных.\n",
    "\n",
    "**Заключение**\n",
    "\n",
    "Код предоставляет гибкую структуру для вычисления различных функций потерь и их производных, что важно для настройки и обучения моделей машинного обучения. Классы MAE, MSE и CE реализуют конкретные функции потерь, подходящие для различных типов задач, таких как регрессия и классификация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# units.py\n",
    "import numpy as np\n",
    "\n",
    "# Класс для Нейрона\n",
    "class Neuron:\n",
    "    # Встроенный метод для инициализации объекта\n",
    "    def __init__(self, weights, bias=None, activation=linear, loss=MSE()):\n",
    "        self.inputs = np.nan\n",
    "        self.weights = np.array(weights)\n",
    "        self.bias = np.float64(bias) if bias is not None else None\n",
    "        self.z = None\n",
    "        self.activation = activation\n",
    "        self.a = None\n",
    "        self.loss_function = loss if loss is not None else MSE()\n",
    "        self.delta = np.nan\n",
    "        self.gradient = {'weights': None, 'bias': None}\n",
    "\n",
    "    # Метод для получения производной активационной функции\n",
    "    def activation_derivative(self, z):\n",
    "        return self.activation(z, derivative=True)\n",
    "\n",
    "    # Метод для подачи/\"прогона\" данных в/через перцептрон, вычисления z и активации (выхода/ответа)\n",
    "    def forward(self, x):\n",
    "        # Сохраняем поданные в перцептрон входные данные в переменной-атрибуте объекта\n",
    "        self.inputs = x\n",
    "        # Рассчитываем взвешенную сумму (z)\n",
    "        self.z = np.dot(self.inputs, self.weights) + (self.bias if self.bias is not None else 0)\n",
    "        # Применяем функцию активации к z\n",
    "        self.a = self.activation(self.z)\n",
    "        return self.a  # возвращаем результат активации (выход/ответ перцептрона output)\n",
    "    \n",
    "    # Метод обратного распространения ошибки\n",
    "    def backward(self, error):\n",
    "        \"\"\"\n",
    "        Выполняет обратное распространение ошибки для корректировки весов и смещений нейрона.\n",
    "\n",
    "        Этот метод вычисляет градиенты для весов и смещений на основе ошибки, полученной на выходе нейрона.\n",
    "        Используется алгоритм обратного распространения ошибки для обновления параметров модели с целью\n",
    "        минимизации функции потерь.\n",
    "\n",
    "        Аргументы:\n",
    "        error -- Ошибка, вычисленная на выходе нейрона, которая отражает расхождение между предсказанными\n",
    "                и истинными значениями.\n",
    "\n",
    "        Процесс:\n",
    "        1. Вычисляется дельта (`delta`), которая представляет собой градиент ошибки по отношению к входам\n",
    "        нейрона, учитывая производные функции потерь и функции активации.\n",
    "        2. Вычисляются градиенты для весов и смещений на основе дельты и входных данных.\n",
    "        \n",
    "        Результаты:\n",
    "        - `self.delta`: Градиент ошибки по отношению к входам.\n",
    "        - `self.gradient['weights']`: Градиент для весов, используемый для корректировки весов модели.\n",
    "        - `self.gradient['bias']`: Градиент для смещения, используемый для корректировки смещения модели.\n",
    "        \"\"\"\n",
    "        self.delta = self.loss_function.loss_derivative(error) * self.activation_derivative(self.z)\n",
    "        self.gradient['weights'] = self.inputs * self.delta\n",
    "        self.gradient['bias'] = np.sum(self.delta, axis=0)\n",
    "    \n",
    "    # Метод для обновления/изменения весов и смещения на основе ошибки\n",
    "    def update(self, learning_rate):\n",
    "        self.weights -= learning_rate * self.gradient['weights']\n",
    "        if self.bias is not None:\n",
    "            self.bias -= learning_rate * self.gradient['bias']\n",
    "\n",
    "    # Метод для обучения\n",
    "    def fit(self, X, y, epochs, learning_rate):\n",
    "        y = y.reshape(-1, 1)\n",
    "        print(f'Процесс обучения из {epochs} эпох')\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            for x, y_true in zip(X, y):    \n",
    "                # Прогон каждого отдельного одного объекта из выборки и получение результата\n",
    "                prediction = self.forward(x)\n",
    "                \n",
    "                # Вычисление ошибки\n",
    "                error = self.loss_function.evaluate_error(y_true, prediction)\n",
    "                loss = self.loss_function.evaluate_loss(y_true, prediction)\n",
    "                epoch_loss += loss\n",
    "                \n",
    "                self.backward(error)\n",
    "                self.update(learning_rate)\n",
    "            \n",
    "            loss = epoch_loss / len(y)\n",
    "            \n",
    "            # Выводим на новой строке только каждую 10-ю эпоху\n",
    "            end = '\\n' if (epochs < 10 or epoch == 0 or (epoch + 1) % (epochs // 10) == 0 or epoch == epochs - 1) else '\\r' \n",
    "            print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss:.4f}', end=end)\n",
    "        print(f'Training completed with Overall Loss {loss:.4f}')\n",
    "    \n",
    "    # Встроенный метод для вызова объекта как функции\n",
    "    def __call__(self, X):\n",
    "        return np.array([self.forward(x) for x in X])\n",
    "\n",
    "    # Метод для получения предсказаний по всей выборке\n",
    "    def predict(self, X):\n",
    "        return self.__call__(X)\n",
    "    \n",
    "    # Встроенный метод для строкового представления объекта\n",
    "    def __str__(self):\n",
    "        # self.forward(self.inputs) if self.inputs is not None else ...  # рассчитываем актуальные значения z и a\n",
    "        return f'Neuron, inputs: {self.inputs}, weights: {self.weights}, bias: {np.float64(self.bias):.2f}, z: {np.float64(self.z):.2f}, ' \\\n",
    "               f'activation: {self.activation.__name__}, a (output): {np.float64(self.a):.2f}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "**Пояснение к коду**\n",
    "\n",
    "Метод backward предназначен для выполнения процесса обратного распространения ошибки в нейронной сети, что является ключевым шагом в процессе обучения модели. Этот метод корректирует веса и смещения (параметры модели) на основе ошибки, вычисленной в процессе прямого распространения и полученной на выходе модели. В данном случае это на самом деле еще не МОР ошибки, так как у нас нет еще сети и слоев в по которым эта ошибка распространияется, но код написан так, потому что дальнейшие действия при разработке класса слоя и класса сети будут иметь похожую логику.\n",
    "\n",
    "Как работает метод:\n",
    "1. **Вычисление дельты (delta):**\n",
    "- `self.delta = self.loss_function.loss_derivative(error) * self.activation_derivative(self.z)`: error — это ошибка, полученная на выходе нейрона, которая измеряет расхождение между предсказанными и истинными значениями.\n",
    "- `self.loss_function.loss_derivative(error)`: Метод, который вычисляет производную функции потерь по отношению к ошибке. Это позволяет понять, как ошибка должна изменяться в зависимости от изменений в выходных данных.\n",
    "- `self.activation_derivative(self.z)`: Метод, который вычисляет производную функции активации по отношению к `z`, где `z` — это взвешенная сумма входов перед применением функции активации.\n",
    "Умножение этих двух значений дает градиент ошибки по отношению к входам нейрона. Этот градиент (self.delta) указывает, насколько сильно необходимо изменить веса и смещения.\n",
    "2.  **Вычисление градиента для весов (weights):**\n",
    "- `self.gradient['weights'] = self.inputs * self.delta`: `self.inputs` — Это массив входных данных.\n",
    "3.  **Вычисление градиента для смещения (bias):**\n",
    "- `self.gradient['bias'] = np.sum(self.delta, axis=0)`\n",
    "- `np.sum(self.delta, axis=0)`: Операция суммирования всех значений дельты по всем примерам в выборке, что дает градиент для смещения. Это указывает, насколько необходимо изменить смещение для уменьшения ошибки.\n",
    "\n",
    "Метод backward является важным элементом алгоритма обратного распространения ошибки (backpropagation), который используется для обучения нейронных сетей. Корректировка весов и смещений на основе градиентов позволяет модели улучшать свои прогнозы и минимизировать ошибку.\n",
    "\n",
    "Этот метод используется в процессе обучения нейронной сети для корректировки параметров модели с целью улучшения точности предсказаний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процесс обучения из 100 эпох\n",
      "Epoch 1/100, Loss: 0.5373\n",
      "Epoch 10/100, Loss: 0.2408\n",
      "Epoch 20/100, Loss: 0.1504\n",
      "Epoch 30/100, Loss: 0.0867\n",
      "Epoch 40/100, Loss: 0.0579\n",
      "Epoch 50/100, Loss: 0.0426\n",
      "Epoch 60/100, Loss: 0.0333\n",
      "Epoch 70/100, Loss: 0.0271\n",
      "Epoch 80/100, Loss: 0.0228\n",
      "Epoch 90/100, Loss: 0.0196\n",
      "Epoch 100/100, Loss: 0.0172\n",
      "Training completed with Overall Loss 0.0172\n",
      "\n",
      "Предсказанные значения: [0 0 0 1], ожидаемые/истинные значения: [0 0 0 1]\n",
      "\n",
      "\"Прогоняем\" по-очереди каждый объект выборки через наш обученный перцептрон\n",
      "Neuron, inputs: [0 0], weights: [3.55 3.51], bias: -5.32, z: -5.32, activation: sigmoid, a (output): 0.00\n",
      "Neuron, inputs: [0 1], weights: [3.55 3.51], bias: -5.32, z: -1.82, activation: sigmoid, a (output): 0.14\n",
      "Neuron, inputs: [1 0], weights: [3.55 3.51], bias: -5.32, z: -1.77, activation: sigmoid, a (output): 0.15\n",
      "Neuron, inputs: [1 1], weights: [3.55 3.51], bias: -5.32, z: 1.73, activation: sigmoid, a (output): 0.85\n"
     ]
    }
   ],
   "source": [
    "# Задача AND\n",
    "# Настройка вывода для удобочитаемости\n",
    "np.set_printoptions(precision=2, suppress=True, threshold=8, edgeitems=1, linewidth=80)\n",
    "\n",
    "# Входные данные и целевая метка (ожидаемый результат)\n",
    "X = np.array([[0, 0], \n",
    "              [0, 1], \n",
    "              [1, 0], \n",
    "              [1, 1]])\n",
    "y = np.array([0, 0, 0, 1])\n",
    "\n",
    "# Объявляем и инициализируем объект класса Neuron с пороговой функцией активации\n",
    "neuron = Neuron(weights=[-0.5, -1.25], bias=1.75, activation=sigmoid)\n",
    "\n",
    "# Обучаем перцептрон\n",
    "neuron.fit(X, y, epochs=100, learning_rate=1)\n",
    "\n",
    "# Предсказание на обучающем примере\n",
    "predictions = neuron(X)\n",
    "print(f'\\nПредсказанные значения: {np.round(predictions).astype(int)}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "print('\\n\"Прогоняем\" по-очереди каждый объект выборки через наш обученный перцептрон')\n",
    "for x in X:\n",
    "    neuron.forward(x)\n",
    "    print(neuron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "**Пояснение к коду**\n",
    "\n",
    "В целом по выводу должно быть все предельно ясно. Мы увеличили кол-во эпох до 100 и добавили в метод fit вывод только каждой 10-й эпохи. В выводе можно увидеть как уменьшается наша ошибка. Предсказанные значения округлены.\n",
    "\n",
    "**Заключение**\n",
    "\n",
    "Четвертый раздел начался с написания класса Neuron и мы разбирали некоторые понятия:\n",
    "1. numpy\n",
    "2. Активационные функции (activations.py)\n",
    "3. Функция потерь (losses.py)\n",
    "\n",
    "Теперь нужно продолжить этот список, и разобраться еще с несколькими важными понятиями которые так или иначе можно объеденить по смыслу в категорию оптимизаторов/\"улучшителей\":\n",
    "\n",
    "4. Оптимизаторы (optimizers.py)\n",
    "5. Инициализаторы весов и смещения (initializers.py)\n",
    "6. Батчи\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "## 5. Оптимизации и улучшения\n",
    "\n",
    "Погружаемся еще глубже в устройство нейронных сетей и кратко разберемся с некоторыми важными понятиями:\n",
    "- Optimizers (Оптимизаторы) — это алгоритмы, которые управляют процессом обновления параметров модели (веса, смещения) во время обучения, чтобы минимизировать функцию потерь.\n",
    "- Initializers (Инициализаторы) — это методы для начальной инициализации параметров модели (веса, смещения) перед началом обучения. От правильной инициализации зависит скорость сходимости и точность модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "### 5.1 Optimizers\n",
    "\n",
    "Optimizers (Оптимизаторы) — это алгоритмы, используемые для настройки параметров модели машинного обучения, таких как веса и смещения, с целью минимизации функции потерь. Они определяют, как и в каком направлении изменяются параметры модели во время процесса обучения. В нашем методе update мы изменияем веса и смещение. Пока мы изменяем их просто на некоторое значение без каких-то оптимизаций. Но так как мы будем реализовывать использовать некоторые алгоритмя оптимизации и они у нас будут в отдельном файле, то можно код метода update также вынести уже сейчас в этот файл.\n",
    "\n",
    "Некоторые виды оптимизаторов:\n",
    "\n",
    "**Gradient Descent (Градиентный спуск)**: Базовый оптимизатор, который обновляет параметры модели в направлении противоположном градиенту функции потерь. Имеет несколько вариаций:\n",
    "- Batch Gradient Descent: Использует весь тренировочный набор данных для каждого обновления параметров.\n",
    "- Stochastic Gradient Descent (SGD): Использует один случайный пример данных для каждого обновления, что делает процесс более шумным, но иногда более эффективным.\n",
    "- Mini-Batch Gradient Descent: Комбинирует подходы, используя небольшие случайные подмножества данных для каждого обновления.\n",
    "\n",
    "**Momentum**: Улучшение градиентного спуска, которое добавляет \"инерцию\" к изменениям параметров, помогая быстрее сходиться и преодолевать локальные минимумы.\n",
    "\n",
    "**RMSprop (Root Mean Square Propagation)**: Адаптирует шаг обучения для каждого параметра, основываясь на средней величине градиентов за последние несколько итераций.\n",
    "\n",
    "**Adam (Adaptive Moment Estimation)**: Один из самых популярных оптимизаторов, который объединяет идеи Momentum и RMSprop, адаптируя шаг обучения для каждого параметра и добавляя моментум для ускорения сходимости.\n",
    "\n",
    "В методе update у нас самый обычный Gradient Descent (Градиентный спуск). Правда мы пока не реализовали возможность использования Batch Gradient Descent и Mini-Batch Gradient Descent. Покак мы просто подаем по одному элементу выборки и на каждом этапе обновляем веса и смещение. Это в целом называется Stochastic Gradient Descent (SGD). Оптимизаторы играют ключевую роль в эффективности и скорости обучения модели, а также могут влиять на точность конечных предсказаний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizers.py\n",
    "import numpy as np\n",
    "\n",
    "# Класс для оптимизаторов\n",
    "class Optimizer:\n",
    "    def update(self, object):\n",
    "        raise NotImplementedError('This method should be overridden by subclasses')\n",
    "\n",
    "class Standard(Optimizer):\n",
    "    def __init__(self, learning_rate=0.1):\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def update(self, object):\n",
    "        object.weights -= self.learning_rate * object.gradient['weights']\n",
    "        if object.bias is not None:\n",
    "            object.bias -= self.learning_rate * object.gradient['bias']\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'\"Standard\"' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "К я и сказал ранее наш класс Standard на самом деле ничего не оптимизирует еще. Он просто меняет веса и смещение на градиент вычисленный на основе ошибки. Это просто общий шаблон. Позже мы просто добавим в наш файл optimizers.py классs SGD и Adam которые уже будут оптимизировать наш процесс изменения весов. Наши оптимизаторы будут содержать некоторые атрибуты и методы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "### 5.2 Initialazers\n",
    "\n",
    "Возможность инициализировать веса вручную довольно полезная возможность на начальных этапах изучения алгоритмов работы, но в целом довольно бесполезная. Пока мы разбирали простые задачи можно было на пальцах считать что у нас на входе и что на выходе и понять процесс обучения. Но при выборках с большим кол-во признаков у объектов, с десятками, а то и сотнями нейронов с нескольких слоях посчитать ни на пальцах ни на калькуляторе это уже невозможно. Поэтому нам нужно инициализировать веса и смещение автоматически по определенному алгоритму. Но самое важное это то, что от инициализации весов зависит очень многое.\n",
    " \n",
    "Initializers (Инициализаторы) — это методы для начальной инициализации параметров модели (веса, смещения) перед началом обучения. От правильной инициализации зависит скорость сходимости и точность модели.\n",
    "\n",
    "Некоторые виды оптимизаторов:\n",
    "\n",
    "**Zeros Initialization**: Инициализация всех параметров нулями. Не рекомендуется для нейронных сетей, так как приводит к одинаковым градиентам.\n",
    "\n",
    "**Random Initialization**: Инициализация параметров случайными значениями из равномерного распределения. Может вызвать проблемы с симметрией, но иногда используется в простых моделях.\n",
    "\n",
    "**Xavier/Glorot Initialization**: Инициализирует параметры с учетом размера слоя, чтобы поддерживать стабильность сигналов во время прямого и обратного распространения.\n",
    "\n",
    "**He Initialization**: Вариант для моделей с функцией активации ReLU, учитывающий большие градиенты в глубоких сетях, что улучшает сходимость."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializers.py\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Initializer:\n",
    "    def __call__(self, shape):\n",
    "        raise NotImplementedError('Initializer must implement this method')\n",
    "\n",
    "class Constant(Initializer):\n",
    "    def __init__(self, value=0):\n",
    "        self.value = value\n",
    "\n",
    "    def __call__(self, shape):\n",
    "        return np.full(shape, self.value)\n",
    "    \n",
    "class RandomNormal(Initializer):\n",
    "    def __init__(self, mean=0.0, stddev=0.05):\n",
    "        self.mean = mean\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def __call__(self, shape):\n",
    "        return np.random.normal(loc=self.mean, scale=self.stddev, size=shape)\n",
    "\n",
    "class RandomUniform(Initializer):\n",
    "    def __init__(self, minval=-0.05, maxval=0.05):\n",
    "        self.minval = minval\n",
    "        self.maxval = maxval\n",
    "\n",
    "    def __call__(self, shape):\n",
    "        return np.random.uniform(self.minval, self.maxval, size=shape)\n",
    "\n",
    "class GlorotNormal(Initializer):\n",
    "    def __call__(self, shape):\n",
    "        fan_in, fan_out = shape\n",
    "        stddev = np.sqrt(2 / (fan_in + fan_out))\n",
    "        return np.random.randn(fan_in, fan_out) * stddev\n",
    "    \n",
    "class GlorotUniform(Initializer):\n",
    "    def __call__(self, shape):\n",
    "        fan_in, fan_out = shape\n",
    "        limit = np.sqrt(6 / (fan_in + fan_out))\n",
    "        return np.random.uniform(-limit, limit, size=shape)\n",
    "    \n",
    "class HeNormal(Initializer):\n",
    "    def __call__(self, shape):\n",
    "        fan_in, fan_out = shape\n",
    "        stddev = np.sqrt(2 / fan_in)\n",
    "        return np.random.randn(*shape) * stddev\n",
    "\n",
    "class HeUniform(Initializer):\n",
    "    def __call__(self, shape):\n",
    "        fan_in, fan_out = shape\n",
    "        limit = np.sqrt(6 / fan_in)\n",
    "        return np.random.uniform(-limit, limit, size=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# units.py\n",
    "import numpy as np\n",
    "\n",
    "# Класс для Нейрона\n",
    "class Neuron:\n",
    "    # Встроенный метод для инициализации объекта\n",
    "    def __init__(self, weights=GlorotUniform(), bias=GlorotUniform(), input_size=2, output_size=1, activation=linear, loss=MSE(), optimizer=Standard()):\n",
    "        self.inputs = np.nan\n",
    "        self.weights = np.array(weights) if isinstance(weights, list) else weights(shape=(input_size, output_size)).flatten()\n",
    "        self.bias = np.float64(bias) if isinstance(bias, (float, int)) else bias(shape=(1, output_size)).flatten()\n",
    "        self.z = None\n",
    "        self.activation = activation\n",
    "        self.a = None\n",
    "        self.loss_function = loss if loss is not None else MSE()\n",
    "        self.delta = np.nan\n",
    "        self.gradient = {'weights': None, 'bias': None}\n",
    "        self.optimizer = optimizer if optimizer is not None else Standard()\n",
    "\n",
    "    # Метод для получения производной активационной функции\n",
    "    def activation_derivative(self, z):\n",
    "        return self.activation(z, derivative=True)\n",
    "\n",
    "    # Метод для подачи/\"прогона\" данных в/через перцептрон, вычисления z и активации (выхода/ответа)\n",
    "    def forward(self, x):\n",
    "        # Сохраняем поданные в перцептрон входные данные в переменной-атрибуте объекта\n",
    "        self.inputs = x\n",
    "        # Рассчитываем взвешенную сумму (z)\n",
    "        self.z = np.dot(self.inputs, self.weights) + (self.bias if self.bias is not None else 0)\n",
    "        # Применяем функцию активации к z\n",
    "        self.a = self.activation(self.z)\n",
    "        return self.a  # возвращаем результат активации (выход/ответ перцептрона output)\n",
    "    \n",
    "    # Метод обратного распространения ошибки\n",
    "    def backward(self, error):\n",
    "        self.delta = self.loss_function.loss_derivative(error) * self.activation_derivative(self.z)\n",
    "        self.gradient['weights'] = self.inputs * self.delta\n",
    "        self.gradient['bias'] = np.sum(self.delta, axis=0)\n",
    "    \n",
    "    # Метод для обновления/изменения весов и смещения\n",
    "    def update(self):\n",
    "        self.optimizer.update(self)\n",
    "\n",
    "    # Метод для обучения\n",
    "    def fit(self, X, y, epochs):\n",
    "        y = y.reshape(-1, 1)\n",
    "        print(f'Процесс обучения из {epochs} эпох')\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            for x, y_true in zip(X, y):    \n",
    "                # Прогон каждого отдельного одного объекта из выборки и получение результата\n",
    "                prediction = self.forward(x)\n",
    "                \n",
    "                # Вычисление ошибки\n",
    "                error = self.loss_function.evaluate_error(y_true, prediction)\n",
    "                loss = self.loss_function.evaluate_loss(y_true, prediction)\n",
    "                epoch_loss += loss\n",
    "                \n",
    "                self.backward(error)\n",
    "                self.update()\n",
    "            \n",
    "            loss = epoch_loss / len(y)\n",
    "            \n",
    "            # Выводим на новой строке только каждую 10-ю эпоху\n",
    "            end = '\\n' if (epochs < 10 or epoch == 0 or (epoch + 1) % (epochs // 10) == 0 or epoch == epochs - 1) else '\\r' \n",
    "            print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss:.4f}', end=end)\n",
    "        print(f'Training completed with Overall Loss {loss:.4f}')\n",
    "    \n",
    "    # Встроенный метод для вызова объекта как функции\n",
    "    def __call__(self, X):\n",
    "        return np.array([self.forward(x) for x in X])\n",
    "\n",
    "    # Метод для получения предсказаний по всей выборке\n",
    "    def predict(self, X):\n",
    "        return self.__call__(X)\n",
    "    \n",
    "    # Встроенный метод для строкового представления объекта\n",
    "    def __str__(self):\n",
    "        # self.forward(self.inputs) if self.inputs is not None else ...  # рассчитываем актуальные значения z и a\n",
    "        return f'Neuron, inputs: {self.inputs}, weights: {self.weights}, bias: {np.float64(self.bias):.2f}, z: {np.float64(self.z):.2f}, ' \\\n",
    "               f'activation: {self.activation.__name__}, a (output): {np.float64(self.a):.2f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начальная инициализация нейрона:\n",
      "Neuron, inputs: nan, weights: [-0.8   0.48], bias: -0.29, z: nan, activation: sigmoid, a (output): nan\n",
      "\n",
      "Процесс обучения из 100 эпох\n",
      "Epoch 1/100, Loss: 0.2766\n",
      "Epoch 10/100, Loss: 0.1431\n",
      "Epoch 20/100, Loss: 0.0833\n",
      "Epoch 30/100, Loss: 0.0563\n",
      "Epoch 40/100, Loss: 0.0417\n",
      "Epoch 50/100, Loss: 0.0327\n",
      "Epoch 60/100, Loss: 0.0267\n",
      "Epoch 70/100, Loss: 0.0225\n",
      "Epoch 80/100, Loss: 0.0194\n",
      "Epoch 90/100, Loss: 0.0170\n",
      "Epoch 100/100, Loss: 0.0151\n",
      "Training completed with Overall Loss 0.0151\n",
      "\n",
      "Предсказанные значения: [0 0 0 1], ожидаемые/истинные значения: [0 0 0 1]\n",
      "\n",
      "\"Прогоняем\" по-очереди каждый объект выборки через наш обученный нейрон\n",
      "Neuron, inputs: [0 0], weights: [3.68 3.65], bias: -5.53, z: -5.53, activation: sigmoid, a (output): 0.00\n",
      "Neuron, inputs: [0 1], weights: [3.68 3.65], bias: -5.53, z: -1.89, activation: sigmoid, a (output): 0.13\n",
      "Neuron, inputs: [1 0], weights: [3.68 3.65], bias: -5.53, z: -1.85, activation: sigmoid, a (output): 0.14\n",
      "Neuron, inputs: [1 1], weights: [3.68 3.65], bias: -5.53, z: 1.79, activation: sigmoid, a (output): 0.86\n"
     ]
    }
   ],
   "source": [
    "# Задача AND\n",
    "# Настройка вывода для удобочитаемости\n",
    "np.set_printoptions(precision=2, suppress=True, threshold=8, edgeitems=1, linewidth=80)\n",
    "\n",
    "# Входные данные и целевая метка (ожидаемый результат)\n",
    "X = np.array([[0, 0], \n",
    "              [0, 1], \n",
    "              [1, 0], \n",
    "              [1, 1]])\n",
    "y = np.array([0, 0, 0, 1])\n",
    "\n",
    "# Объявляем и инициализируем объект класса Neuron с пороговой функцией активации\n",
    "neuron = Neuron(activation=sigmoid, optimizer=Standard(learning_rate=1))\n",
    "print(f'Начальная инициализация нейрона:\\n{neuron}')\n",
    "print()\n",
    "# Обучаем нейрон\n",
    "neuron.fit(X, y, epochs=100)\n",
    "\n",
    "# Предсказание на обучающем примере\n",
    "predictions = neuron(X)\n",
    "print(f'\\nПредсказанные значения: {np.round(predictions.flatten()).astype(int)}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "print('\\n\"Прогоняем\" по-очереди каждый объект выборки через наш обученный нейрон')\n",
    "for x in X:\n",
    "    neuron.forward(x)\n",
    "    print(neuron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"data/styles/styles.css\">\n",
    "\n",
    "### 5.3 Батчи\n",
    "\n",
    "Батчи (batches) — это небольшие подвыборки данных, на которые делится общий тренировочный набор при обучении модели. Вместо того чтобы обучать модель на всем наборе данных сразу, что может быть очень затратно по времени и ресурсам, обучение проводится на отдельных батчах. Это позволяет:\n",
    "\n",
    "- Ускорить обучение — поскольку обновление весов происходит реже (если, конечно, сравнивать с вариантом обновления весов после каждого объекта выборки).\n",
    "- Снизить потребление памяти — так как обрабатывается только часть данных за раз. Тут тоже следует уточнить, что сравниваем не с тем как мы до этого обновляли веса, а о том варианте когда обрабатывется сразу весь набор данных. Мы же до этого использовали только стохастический градентный спуск. \n",
    "- Улучшить обобщающую способность модели — за счет добавления случайности и предотвращения переобучения. Вот это очень важный момент. Когда мы обрабатываем каждый объект выборки по-отдельности может возникнуть ситуация, когда наша сеть вместо выявления некой общей закономерности в данных просто начнет так сказать \"запоминать\" правильные ответы. Тут термин \"запоминать\" может быть не совсем понятен, но смысл в том что при переобучении сеть будет отлично классифицировать обучающую выборку но при этом показывать плохие результаты на тестовой выборке. Это и говорит о том, что сеть не выявила некую общую закономерность, а максимально точно подобрала веса конкретно для обучающей выборки.\n",
    "\n",
    "Обычно размер батча (batch size) выбирается экспериментально, исходя из доступных ресурсов и специфики задачи.\n",
    "\n",
    "Еще раз повторю, что до этого мы пользовались только стохастическим градиентным спуском, это когда подается по одному объекту, на этом объекте вычисляется ошибка и сразу же обновляются веса. Поэтому зазбиение на mini-batch нам никак не уменьшит потребление памяти, но вот со скоростью и с переобучением поможет.\n",
    "\n",
    "Для реализации батчей нам нужно: \n",
    "- Немного изменить метод forward и predict.\n",
    "- Ввести некоторые новые аттрибуты. \n",
    "- Доработать метод fit.\n",
    "\n",
    "Так же мы попутно добавим возможность перемешивать наши данные на каждой эпохе обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# units.py\n",
    "import numpy as np\n",
    "\n",
    "# Класс для Нейрона\n",
    "class Neuron:\n",
    "    # Встроенный метод для инициализации объекта\n",
    "    def __init__(self, weights=GlorotUniform(), bias=GlorotUniform(), input_size=2, output_size=1, activation=linear, loss=MSE(), optimizer=Standard()):\n",
    "        self.Inputs = np.nan\n",
    "        self.weights = np.array([weights]) if isinstance(weights, list) else weights(shape=(input_size, output_size))\n",
    "        self.bias = np.float64(bias) if isinstance(bias, (float, int)) else bias(shape=(1, output_size)).flatten()\n",
    "        self.Z = np.nan  # массив значений z по всему батчу\n",
    "        self.activation = activation\n",
    "        self.A = np.nan # массив значений a (активаций) по всему батчу\n",
    "        self.loss_function = loss if loss is not None else MSE()\n",
    "        self.delta = np.nan\n",
    "        self.gradient = {'weights': None, 'bias': None}\n",
    "        self.optimizer = optimizer if optimizer is not None else Standard()\n",
    "\n",
    "    @property\n",
    "    # Последний объект прошедший через нейрон\n",
    "    def inputs(self):\n",
    "        return self.Inputs[-1] if self.Inputs is not np.nan else np.nan\n",
    "\n",
    "    @property\n",
    "    # Значение z последнего объекта прошедшего через нейрон\n",
    "    def z(self):\n",
    "        return self.Z[-1].item() if self.Z is not np.nan else np.nan\n",
    "    \n",
    "    @property\n",
    "    # Значение a (активации) последнего объекта прошедшего через нейрон\n",
    "    def a(self):\n",
    "        return self.A[-1].item() if self.A is not np.nan else np.nan\n",
    "\n",
    "    # Метод для получения производной активационной функции\n",
    "    def activation_derivative(self, z):\n",
    "        return self.activation(z, derivative=True)\n",
    "\n",
    "    # Метод для подачи/\"прогона\" данных в/через перцептрон, вычисления z и активации (выхода/ответа)\n",
    "    def forward(self, X, training=True):\n",
    "        self.Inputs = X\n",
    "        self.Z = np.dot(self.Inputs, self.weights) + (self.bias if self.bias is not None else 0)\n",
    "        self.A = self.activation(self.Z)\n",
    "        return self.A\n",
    "    \n",
    "    # Метод обратного распространения ошибки\n",
    "    def backward(self, error):\n",
    "        self.delta = self.loss_function.loss_derivative(error) * self.activation_derivative(self.Z)\n",
    "        self.gradient['weights'] = np.dot(self.Inputs.T, self.delta)\n",
    "        self.gradient['bias'] = np.sum(self.delta, axis=0)\n",
    "    \n",
    "    # Метод для обновления/изменения весов и смещения\n",
    "    def update(self):\n",
    "        self.optimizer.update(self)\n",
    "\n",
    "    # Метод для обучения\n",
    "    def fit(self, X, y, epochs=10, batch_size=1, shuffle=True):\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        y = y.reshape(-1, 1)\n",
    "        X_len = X.shape[0]\n",
    "        for epoch in range(epochs):\n",
    "            if shuffle:\n",
    "                permutation = np.random.permutation(X_len)\n",
    "                X_shuffled = X[permutation]\n",
    "                y_shuffled = y[permutation]\n",
    "            else:\n",
    "                X_shuffled = X\n",
    "                y_shuffled = y\n",
    "            \n",
    "            epoch_loss = 0\n",
    "            num_batches = 0\n",
    "            \n",
    "            for i in range(0, X_len, (batch_size if batch_size is not None else X_len)):\n",
    "                num_batches += 1\n",
    "                X_batch = X_shuffled[i:i+(batch_size if batch_size is not None else X_len)]\n",
    "                y_batch = y_shuffled[i:i+(batch_size if batch_size is not None else X_len)]\n",
    "                \n",
    "                predictions_batch = self.forward(X_batch)\n",
    "                error = self.loss_function.evaluate_error(y_batch, predictions_batch)\n",
    "                loss = self.loss_function.evaluate_loss(y_batch, predictions_batch)\n",
    "                epoch_loss += loss\n",
    "                \n",
    "                self.backward(error)\n",
    "                self.update()\n",
    "            \n",
    "            loss = epoch_loss / num_batches\n",
    "            \n",
    "            # Выводим на новой строке только каждую 10-ю эпоху\n",
    "            end = '\\n' if (epochs < 10 or epoch == 0 or (epoch + 1) % (epochs // 10) == 0 or epoch == epochs - 1) else '\\r' \n",
    "            print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss:.4f}', end=end)\n",
    "        print(f'Training completed with Overall Loss {loss:.4f}')\n",
    "    \n",
    "    # Встроенный метод для вызова объекта как функции\n",
    "    def __call__(self, X, training=False):\n",
    "        return self.forward(X, training)\n",
    "\n",
    "    # Метод для получения предсказаний по всей выборке\n",
    "    def predict(self, X):\n",
    "        return self.forward(X, training=False)\n",
    "    \n",
    "    # Встроенный метод для строкового представления объекта\n",
    "    def __str__(self):\n",
    "        # self.forward(self.inputs) if self.inputs is not None else ...  # рассчитываем актуальные значения z и a\n",
    "        return f'Neuron, inputs: {self.inputs}, weights: {self.weights.T.flatten()}, bias: {np.float64(self.bias):.2f}, z: {np.float64(self.z):.2f}, ' \\\n",
    "               f'activation: {self.activation.__name__}, a (output): {np.float64(self.a):.2f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начальная инициализация нейрона:\n",
      "Neuron, inputs: nan, weights: [-1.11  0.8 ], bias: 0.88, z: nan, activation: sigmoid, a (output): nan\n",
      "\n",
      "Epoch 1/100, Loss: 0.4074\n",
      "Epoch 10/100, Loss: 0.1570\n",
      "Epoch 20/100, Loss: 0.0883\n",
      "Epoch 30/100, Loss: 0.0588\n",
      "Epoch 40/100, Loss: 0.0431\n",
      "Epoch 50/100, Loss: 0.0336\n",
      "Epoch 60/100, Loss: 0.0274\n",
      "Epoch 70/100, Loss: 0.0230\n",
      "Epoch 80/100, Loss: 0.0197\n",
      "Epoch 90/100, Loss: 0.0173\n",
      "Epoch 100/100, Loss: 0.0153\n",
      "Training completed with Overall Loss 0.0153\n",
      "\n",
      "Предсказанные значения: [0 0 0 1], ожидаемые/истинные значения: [0 0 0 1]\n",
      "\n",
      "\"Прогоняем\" по-очереди каждый объект выборки через наш обученный нейрон\n",
      "Neuron, inputs: [0 0], weights: [3.67 3.63], bias: -5.51, z: -5.51, activation: sigmoid, a (output): 0.00\n",
      "Neuron, inputs: [0 1], weights: [3.67 3.63], bias: -5.51, z: -1.88, activation: sigmoid, a (output): 0.13\n",
      "Neuron, inputs: [1 0], weights: [3.67 3.63], bias: -5.51, z: -1.84, activation: sigmoid, a (output): 0.14\n",
      "Neuron, inputs: [1 1], weights: [3.67 3.63], bias: -5.51, z: 1.79, activation: sigmoid, a (output): 0.86\n"
     ]
    }
   ],
   "source": [
    "# Задача AND\n",
    "# Настройка вывода для удобочитаемости\n",
    "np.set_printoptions(precision=2, suppress=True, threshold=8, edgeitems=1, linewidth=80)\n",
    "\n",
    "# Входные данные и целевая метка (ожидаемый результат)\n",
    "X = np.array([[0, 0], \n",
    "              [0, 1], \n",
    "              [1, 0], \n",
    "              [1, 1]])\n",
    "y = np.array([0, 0, 0, 1])\n",
    "\n",
    "# Объявляем и инициализируем объект класса Neuron с пороговой функцией активации\n",
    "neuron = Neuron(activation=sigmoid, optimizer=Standard(learning_rate=1))\n",
    "print(f'Начальная инициализация нейрона:\\n{neuron}')\n",
    "print()\n",
    "# Обучаем нейрон\n",
    "neuron.fit(X, y, epochs=100, shuffle=False)\n",
    "\n",
    "# Предсказание на обучающем примере\n",
    "predictions = neuron(X)\n",
    "print(f'\\nПредсказанные значения: {np.round(predictions.flatten()).astype(int)}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "print('\\n\"Прогоняем\" по-очереди каждый объект выборки через наш обученный нейрон')\n",
    "for x in X:\n",
    "    neuron.forward(np.array([x]))\n",
    "    print(neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начальная инициализация нейрона:\n",
      "Neuron, inputs: nan, weights: [0.86 0.06], bias: 1.20, z: nan, activation: sigmoid, a (output): nan\n",
      "\n",
      "Epoch 1/100, Loss: 0.4987\n",
      "Epoch 10/100, Loss: 0.2205\n",
      "Epoch 20/100, Loss: 0.1637\n",
      "Epoch 30/100, Loss: 0.1351\n",
      "Epoch 40/100, Loss: 0.1151\n",
      "Epoch 50/100, Loss: 0.1005\n",
      "Epoch 60/100, Loss: 0.0892\n",
      "Epoch 70/100, Loss: 0.0803\n",
      "Epoch 80/100, Loss: 0.0730\n",
      "Epoch 90/100, Loss: 0.0668\n",
      "Epoch 100/100, Loss: 0.0615\n",
      "Training completed with Overall Loss 0.0615\n",
      "\n",
      "Предсказанные значения: [0 0 0 1], ожидаемые/истинные значения: [0 0 0 1]\n",
      "\n",
      "\"Прогоняем\" по-очереди каждый объект выборки через наш обученный нейрон\n",
      "Neuron, inputs: [0 0], weights: [1.79 1.76], bias: -2.82, z: -2.82, activation: sigmoid, a (output): 0.06\n",
      "Neuron, inputs: [0 1], weights: [1.79 1.76], bias: -2.82, z: -1.06, activation: sigmoid, a (output): 0.26\n",
      "Neuron, inputs: [1 0], weights: [1.79 1.76], bias: -2.82, z: -1.03, activation: sigmoid, a (output): 0.26\n",
      "Neuron, inputs: [1 1], weights: [1.79 1.76], bias: -2.82, z: 0.73, activation: sigmoid, a (output): 0.67\n"
     ]
    }
   ],
   "source": [
    "# Задача AND\n",
    "# Настройка вывода для удобочитаемости\n",
    "np.set_printoptions(precision=2, suppress=True, threshold=8, edgeitems=1, linewidth=80)\n",
    "\n",
    "# Входные данные и целевая метка (ожидаемый результат)\n",
    "X = np.array([[0, 0], \n",
    "              [0, 1], \n",
    "              [1, 0], \n",
    "              [1, 1]])\n",
    "y = np.array([0, 0, 0, 1])\n",
    "\n",
    "# Объявляем и инициализируем объект класса Neuron с пороговой функцией активации\n",
    "neuron = Neuron(activation=sigmoid, optimizer=Standard(learning_rate=1))\n",
    "print(f'Начальная инициализация нейрона:\\n{neuron}')\n",
    "print()\n",
    "# Обучаем нейрон\n",
    "neuron.fit(X, y, epochs=100, batch_size=None)\n",
    "\n",
    "# Предсказание на обучающем примере\n",
    "predictions = neuron(X)\n",
    "print(f'\\nПредсказанные значения: {np.round(predictions.flatten()).astype(int)}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "print('\\n\"Прогоняем\" по-очереди каждый объект выборки через наш обученный нейрон')\n",
    "for x in X:\n",
    "    neuron.forward(np.array([x]))\n",
    "    print(neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-14.61310403 104.96954537]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(0) # псевдослучайные числа образуют одну и ту же последовательность (при каждом запуске)\n",
    "x = np.arange(-1.0, 1.0, 0.1) # аргумент [-1; 1] с шагом 0,1\n",
    "\n",
    "\n",
    "model_a = lambda xx, ww: (ww[0] + ww[1] * xx) # модель\n",
    "Y = -5.2 + 0.7 * x + np.random.normal(0, 0.1, len(x)) # вектор целевых значений\n",
    "\n",
    "X = np.array([[1, xi] for xi in x])\n",
    "w = np.power(X.T@X, -1)@X.T@Y\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.12132278  4.16006063 -0.35256616 -4.19339165]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(0) # псевдослучайные числа образуют одну и ту же последовательность (при каждом запуске)\n",
    "x = np.arange(-1.0, 1.0, 0.1) # аргумент [-1; 1] с шагом 0,1\n",
    "\n",
    "\n",
    "model_a = lambda xx, ww: (ww[0] + ww[1] * xx + ww[2] * xx ** 2 + ww[3] * xx ** 3) # модель\n",
    "Y = np.sin(x * 5) + 2 * x + np.random.normal(0, 0.1, len(x)) # вектор целевых значений\n",
    "\n",
    "X = np.array([[1, xx, xx**2, xx**3] for xx in x]) # обучающая выборка для поиска коэффициентов w модели a\n",
    "\n",
    "w = np.linalg.solve(X.T@X, X.T@Y)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [5, 0, -1]\n"
     ]
    }
   ],
   "source": [
    "import sympy as sp\n",
    "\n",
    "# Координаты точек\n",
    "points = [[7, 5], [-3, 5]]\n",
    "\n",
    "# Объявляем переменные\n",
    "w1, w2 = sp.symbols('w1 w2')  # символьные переменные для коэффициентов w1 и w2\n",
    "w0 = 5  # допустим, что смещение w0 = 3\n",
    "\n",
    "# Составляем уравнения на основе координат точек: w1*x1 + w2*x2 + w0 = 0\n",
    "equations = [sp.Eq(w1*x1 + w2*x2 + w0, 0) for x1, x2 in points]\n",
    "\n",
    "# Решаем систему уравнений для w1 и w2\n",
    "solution = sp.solve(equations, (w1, w2))\n",
    "\n",
    "print(f'w = [{w0}, {solution[w1]}, {solution[w2]}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sympy as sp\n",
    "\n",
    "# Координаты точек\n",
    "points = [[7, 5], [-3, 5]]\n",
    "\n",
    "# Объявляем переменные\n",
    "w1, w2 = sp.symbols('w1 w2')  # символьные переменные для коэффициентов w1 и w2\n",
    "w0 = -5  # смещение w0\n",
    "\n",
    "# Составляем уравнения на основе координат точек\n",
    "equations = [sp.Eq(w1*x1 + w2*x2 + w0, 0) for x1, x2 in points]\n",
    "\n",
    "# Решаем систему уравнений для w1 и w2\n",
    "solution = sp.solve(equations, (w1, w2))\n",
    "\n",
    "w1_value = solution[w1]\n",
    "w2_value = solution[w2]\n",
    "\n",
    "# Определяем диапазон значений x для построения прямой\n",
    "x_values = np.linspace(-10, 10, 400)\n",
    "y_values = - (w1_value * x_values + w0) / w2_value\n",
    "\n",
    "# Создаем график\n",
    "plt.figure(figsize=(10, 10))  # Размер графика можно настроить по вашему усмотрению\n",
    "plt.plot(x_values, y_values, label=f'Прямая: {w1_value:.2f}x1 + {w2_value:.2f}x2 + {w0} = 0')\n",
    "\n",
    "# Отмечаем точки\n",
    "x_coords, y_coords = zip(*points)\n",
    "plt.scatter(x_coords, y_coords, color='red', zorder=5)\n",
    "for (x, y) in points:\n",
    "    plt.text(x, y, f'({x}, {y})', fontsize=12, verticalalignment='bottom')\n",
    "\n",
    "# Настройки графика\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.title('График прямой')\n",
    "plt.axhline(0, color='black', linewidth=0.5)\n",
    "plt.axvline(0, color='black', linewidth=0.5)\n",
    "plt.grid(color='gray', linestyle='--', linewidth=0.5)\n",
    "plt.legend()\n",
    "\n",
    "# Устанавливаем равные масштабы для осей\n",
    "plt.axis('equal')\n",
    "\n",
    "# Настраиваем метки осей с шагом 1\n",
    "plt.xticks(np.arange(-10, 11, 1))  # Устанавливаем метки оси x от -10 до 10 с шагом 1\n",
    "plt.yticks(np.arange(-10, 11, 1))  # Устанавливаем метки оси y от -10 до 10 с шагом 1\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
